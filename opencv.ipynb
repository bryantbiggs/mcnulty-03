{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "#import cv2\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from scipy.ndimage import imread\n",
    "from scipy.misc import toimage\n",
    "\n",
    "from skimage import data, io, filters\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import os\n",
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join, exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_mat = loadmat('data/train_32x32.mat')['X']\n",
    "# train_labels = loadmat('data/train_32x32.mat')['y']\n",
    "# shape_train = train_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test_mat = loadmat('data/test_32x32.mat')['X']\n",
    "#test_labels = loadmat('data/test_32x32.mat')['y']\n",
    "#shape_test = test_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert images to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = '''\n",
    "def img(ind, which_set):\n",
    "    if which_set == 'test':\n",
    "        return test_mat[:,:,:,ind]\n",
    "    else:\n",
    "        return train_mat[:,:,:,ind]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test_gray32_path = 'data/test/gray32_gray'\n",
    "#train_gray32_path = 'data/train/gray32_gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = '''\n",
    "def make_grayscale(gray_path, img_set):\n",
    "    \n",
    "    # if output directory doesn't exist, make it\n",
    "    if not exists(gray_path):\n",
    "        makedirs(gray_path)\n",
    "        \n",
    "    # get length of image set\n",
    "    _, _, _, mat_len = img_set.shape\n",
    "    \n",
    "    for i in range(mat_len):\n",
    "        im = Image.fromarray(img(i, 'train'))\n",
    "        im = im.convert('L') #makes it greyscale\n",
    "        im.save('data/test/{0}.png'.format(str(i)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make_grayscale(test_gray32_path, test_mat)\n",
    "# make_grayscale(train_gray32_path, train_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import matplotlib.image as mpimg\n",
    "#imgplot = plt.imshow(img(3,'train'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return list of image names from path specified\n",
    "#def get_imgs(dir_path):\n",
    "#    return [f for f in listdir(dir_path) if isfile(join(dir_path, f)) if f.endswith('.png')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import scipy.io as sio\n",
    "\n",
    "#SVHN_train_RGB = sio.loadmat('data/train_32x32.mat', squeeze_me=True, struct_as_record=False)\n",
    "#SVHN_test_RGB = sio.loadmat('data/test_32x32.mat', squeeze_me=True, struct_as_record=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#SVHN_train = (np.sum(SVHN_train_RGB['X'],2)/3)\n",
    "#SVHN_test = (np.sum(SVHN_test_RGB['X'],2)/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Converting Labels to One Hot Encoding and Image Matrix to favourable dimensions\n",
    "\"\"\"\n",
    "_ = '''\n",
    "def reformat(data, Y):\n",
    "    xtrain = []\n",
    "    trainLen = data.shape[3]\n",
    "    for x in range(trainLen):\n",
    "        xtrain.append(data[:,:,:,x])\n",
    "    xtrain = np.asarray(xtrain)\n",
    "    Ytr=[]\n",
    "    for el in Y:\n",
    "        temp=np.zeros(10)\n",
    "        if el==10:\n",
    "            temp[0]=1\n",
    "        elif el==1:\n",
    "            temp[1]=1\n",
    "        elif el==2:\n",
    "            temp[2]=1\n",
    "        elif el==3:\n",
    "            temp[3]=1\n",
    "        elif el==4:\n",
    "            temp[4]=1\n",
    "        elif el==5:\n",
    "            temp[5]=1\n",
    "        elif el==6:\n",
    "            temp[6]=1\n",
    "        elif el==7:\n",
    "            temp[7]=1\n",
    "        elif el==8:\n",
    "            temp[8]=1\n",
    "        elif el==9:\n",
    "            temp[9]=1\n",
    "        Ytr.append(temp)\n",
    "    return xtrain, np.asarray(Ytr)\n",
    "\n",
    "train_data, train_labels = reformat(train_data, train_labels)\n",
    "test_data, test_labels = reformat(test_data, test_labels)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#(dim1,dim2,nImages)=SVHN_train.shape\n",
    "#SVHN_train_V = np.zeros((nImages,dim1*dim2))\n",
    "#for i in range(0,nImages):\n",
    "#    SVHN_train_V[i,:]=SVHN_train[:,:,i].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#SVHN_train_V.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#svm_clf = SVC(gamma=0.001, C=100.)\n",
    "#svm_mdl = svm_clf.fit(x_train2d[:-1], y_train[:-1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.metrics import accuracy_score\n",
    "\n",
    "#accuracy_score(y_test, svm_mdl.predict(x_test2d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = '''\n",
    "cap = cv2.VideoCapture(0) # number is the numbered sequence for your video input (if you have multiple)\n",
    "                          # you can also replace the 0 with a file name and load a file\n",
    "\n",
    "# output to file\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 20.0, (640,480)) \n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # covert to grayscale\n",
    "    grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # write to file\n",
    "    #out.write(frame)\n",
    "    \n",
    "    cv2.imshow('frame', frame) #normal\n",
    "    cv2.imshow('gray', grey) #grayscale\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.DestroyAllWindows()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "            #img obj, start, stop,      color,       line-width  \n",
    "#cv2.rectangle(img, (15,25), (150,150), (255,255,255), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3, 73257) (73257, 1)\n",
      "(32, 32, 3, 26032) (26032, 1)\n",
      "(32, 32, 3, 1) (1,)\n"
     ]
    }
   ],
   "source": [
    "train_data = loadmat('data/train_32x32.mat', variable_names='X').get('X')\n",
    "train_labels = loadmat('data/train_32x32.mat', variable_names='y').get('y')\n",
    "test_data = loadmat('data/test_32x32.mat', variable_names='X').get('X')\n",
    "test_labels = loadmat('data/test_32x32.mat', variable_names='y').get('y')\n",
    "extra_data = loadmat('data/extra_32x32.mat', variable_names='X').get('X')[:,:,:,:1]\n",
    "extra_labels = loadmat('data/extra_32x32.mat', variable_names='y').get('y')[:1]\n",
    "\n",
    "print(train_data.shape, train_labels.shape)\n",
    "print(test_data.shape, test_labels.shape)\n",
    "print(extra_data.shape, extra_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels[train_labels == 10] = 0\n",
    "test_labels[test_labels == 10] = 0\n",
    "extra_labels[extra_labels == 10] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69257, 32, 32, 3) (69257,)\n",
      "(26032, 32, 32, 3) (26032,)\n",
      "(4001, 32, 32, 3) (4001,)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed()\n",
    "\n",
    "n_labels = 10\n",
    "valid_index = []\n",
    "valid_index2 = []\n",
    "train_index = []\n",
    "train_index2 = []\n",
    "for i in np.arange(n_labels):\n",
    "    valid_index.extend(np.where(train_labels[:,0] == (i))[0][:400].tolist())\n",
    "    train_index.extend(np.where(train_labels[:,0] == (i))[0][400:].tolist())\n",
    "    valid_index2.extend(np.where(extra_labels[:,0] == (i))[0][:200].tolist())\n",
    "    train_index2.extend(np.where(extra_labels[:,0] == (i))[0][200:].tolist())\n",
    "\n",
    "random.shuffle(valid_index)\n",
    "random.shuffle(train_index)\n",
    "random.shuffle(valid_index2)\n",
    "random.shuffle(train_index2)\n",
    "\n",
    "valid_data = np.concatenate((extra_data[:,:,:,valid_index2], train_data[:,:,:,valid_index]), axis=3).transpose((3,0,1,2))\n",
    "valid_labels = np.concatenate((extra_labels[valid_index2,:], train_labels[valid_index,:]), axis=0)[:,0]\n",
    "train_data_t = np.concatenate((extra_data[:,:,:,train_index2], train_data[:,:,:,train_index]), axis=3).transpose((3,0,1,2))\n",
    "train_labels_t = np.concatenate((extra_labels[train_index2,:], train_labels[train_index,:]), axis=0)[:,0]\n",
    "test_data = test_data.transpose((3,0,1,2))\n",
    "test_labels = test_labels[:,0]\n",
    "\n",
    "print(train_data_t.shape, train_labels_t.shape)\n",
    "print(test_data.shape, test_labels.shape)\n",
    "print(valid_data.shape, valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69257, 32, 32) (69257,)\n",
      "(26032, 32, 32) (26032,)\n",
      "(4001, 32, 32) (4001,)\n"
     ]
    }
   ],
   "source": [
    "image_size = 32  # Pixel width and height.\n",
    "pixel_depth = 255.0  # Number of levels per pixel.\n",
    "\n",
    "def im2gray(image):\n",
    "    '''Normalize images'''\n",
    "    image = image.astype(float)\n",
    "    # Use the Conversion Method in This Paper:\n",
    "    # [http://www.eyemaginary.com/Rendering/TurnColorsGray.pdf]\n",
    "    image_gray = np.dot(image, [[0.2989],[0.5870],[0.1140]])\n",
    "    return image_gray\n",
    "\n",
    "train_data_c = im2gray(train_data_t)[:,:,:,0]\n",
    "test_data_c = im2gray(test_data)[:,:,:,0]\n",
    "valid_data_c = im2gray(valid_data)[:,:,:,0]\n",
    "\n",
    "print(train_data_c.shape, train_labels_t.shape)\n",
    "print(test_data_c.shape, test_labels.shape)\n",
    "print(valid_data_c.shape, valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69257, 32, 32) (69257,)\n",
      "(26032, 32, 32) (26032,)\n",
      "(4001, 32, 32) (4001,)\n"
     ]
    }
   ],
   "source": [
    "def GCN(image, min_divisor=1e-4):\n",
    "    \"\"\"Global Contrast Normalization\"\"\"\n",
    "    \n",
    "    imsize = image.shape[0]\n",
    "    mean = np.mean(image, axis=(1,2), dtype=float)\n",
    "    std = np.std(image, axis=(1,2), dtype=float, ddof=1)\n",
    "    std[std < min_divisor] = 1.\n",
    "    image_GCN = np.zeros(image.shape, dtype=float)\n",
    "    \n",
    "    for i in np.arange(imsize):\n",
    "        image_GCN[i,:,:] = (image[i,:,:] - mean[i]) / std[i]\n",
    "        \n",
    "    return image_GCN\n",
    "\n",
    "train_data_GCN = GCN(train_data_c)\n",
    "test_data_GCN = GCN(test_data_c)\n",
    "valid_data_GCN = GCN(valid_data_c)\n",
    "\n",
    "print(train_data_GCN.shape, train_labels_t.shape)\n",
    "print(test_data_GCN.shape, test_labels.shape)\n",
    "print(valid_data_GCN.shape, valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.rcParams['figure.figsize'] = (15.0, 15.0)\n",
    "#f, ax = plt.subplots(nrows=1, ncols=10)\n",
    "\n",
    "#for i, j in enumerate(np.random.randint(0, train_labels_t.shape[0], size=10)):\n",
    "#    ax[i].axis('off')\n",
    "#    ax[i].set_title(train_labels_t[j], loc='center')\n",
    "#    ax[i].imshow(train_data_GCN[j,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed pickle size: 263037004\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'SVHN.pickle'\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    #'train_dataset': train_data_GCN,\n",
    "    'train_labels': train_labels_t,\n",
    "    'valid_dataset': valid_data_GCN,\n",
    "    'valid_labels': valid_labels,\n",
    "    'test_dataset': test_data_GCN,\n",
    "    'test_labels': test_labels,\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise\n",
    "    \n",
    "statinfo = os.stat(pickle_file)\n",
    "print('Compressed pickle size:', statinfo.st_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed pickle size: 1638400185\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'SVHN1.pickle'\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'train_dataset1': train_data_GCN[:200000],\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise\n",
    "    \n",
    "statinfo = os.stat(pickle_file)\n",
    "print('Compressed pickle size:', statinfo.st_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed pickle size: 1638400185\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'SVHN2.pickle'\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'train_dataset2': train_data_GCN[200000:400000],\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise\n",
    "    \n",
    "statinfo = os.stat(pickle_file)\n",
    "print('Compressed pickle size:', statinfo.st_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed pickle size: 1625194681\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'SVHN3.pickle'\n",
    "\n",
    "try:\n",
    "  f = open(pickle_file, 'wb')\n",
    "  save = {\n",
    "    'train_dataset3': train_data_GCN[400000:],\n",
    "    }\n",
    "  pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "  f.close()\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_file, ':', e)\n",
    "  raise\n",
    "    \n",
    "statinfo = os.stat(pickle_file)\n",
    "print('Compressed pickle size:', statinfo.st_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# logistic regression classifier\n",
    "clf = SGDClassifier(loss='hinge', penalty='l2', alpha=0.001, shuffle=True, verbose=0, \n",
    "                    n_jobs=4, random_state=None, learning_rate='optimal')\n",
    "\n",
    "clf.fit(train_data_c.reshape(train_data_GCN.shape[0],-1), train_labels_t)\n",
    "\n",
    "train_prediction = clf.predict(train_data_GCN.reshape(train_data_GCN.shape[0],-1))\n",
    "valid_prediction = clf.predict(valid_data_GCN.reshape(valid_data_GCN.shape[0],-1))\n",
    "\n",
    "print('Training score is', clf.score(train_data_GCN.reshape(train_data_GCN.shape[0],-1), train_labels_t))\n",
    "print('Validation score is', clf.score(valid_data_GCN.reshape(valid_data_GCN.shape[0],-1), valid_labels))\n",
    "\n",
    "print('Classification report of training data:\\n', classification_report(train_labels_t, train_prediction))\n",
    "print('Confusion Matrix of training data:\\n', confusion_matrix(train_labels_t, train_prediction))\n",
    "\n",
    "print('Classification report of validation data:\\n', classification_report(valid_labels, valid_prediction))\n",
    "print('Confusion Matrix of validation data:\\n', confusion_matrix(valid_labels, valid_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm_clf = SVC(gamma=0.001, C=100.)\n",
    "svm_mdl = svm_clf.fit(train_data_c.reshape(train_data_GCN.shape[0],-1), train_labels_t)  lo\n",
    "\n",
    "train_prediction = svm_mdl.predict(train_data_GCN.reshape(train_data_GCN.shape[0],-1))\n",
    "valid_prediction = svm_mdl.predict(valid_data_GCN.reshape(valid_data_GCN.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
