{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pickled Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape: (7326,)\n",
      "Testing labels shape:  (2603,)\n"
     ]
    }
   ],
   "source": [
    "directory = 'generated_data'\n",
    "\n",
    "train_labels = np.load('{0}/train_labels.dat'.format(directory))\n",
    "test_labels = np.load('{0}/test_labels.dat'.format(directory))\n",
    "print('Training labels shape: {0}'.format(train_labels.shape))\n",
    "print('Testing labels shape:  {0}'.format(test_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Custom Conversion Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Conversion training shape: (7326, 640)\n",
      "Custom Conversion testing shape:  (2603, 640)\n"
     ]
    }
   ],
   "source": [
    "train_CustGray_2d = np.load('{0}/train_CustGray_2d.dat'.format(directory))\n",
    "test_CustGray_2d = np.load('{0}/test_CustGray_2d.dat'.format(directory))\n",
    "print('Custom Conversion training shape: {0}'.format(train_CustGray_2d.shape))\n",
    "print('Custom Conversion testing shape:  {0}'.format(test_CustGray_2d.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Otsu's Binarization Threshold Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Otsu training shape: (7326, 640)\n",
      "Otsu testing shape:  (2603, 640)\n"
     ]
    }
   ],
   "source": [
    "train_OBT_2d = np.load('{0}/train_OBT_2d.dat'.format(directory))\n",
    "test_OBT_2d = np.load('{0}/test_OBT_2d.dat'.format(directory))\n",
    "print('Otsu training shape: {0}'.format(train_OBT_2d.shape))\n",
    "print('Otsu testing shape:  {0}'.format(test_OBT_2d.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Adaptive Mean Threshold Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive mean training shape: (7326, 640)\n",
      "Adaptive mean testing shape:  (2603, 640)\n"
     ]
    }
   ],
   "source": [
    "train_AMT_2d = np.load('{0}/train_AMT_2d.dat'.format(directory))\n",
    "test_AMT_2d = np.load('{0}/test_AMT_2d.dat'.format(directory))\n",
    "print('Adaptive mean training shape: {0}'.format(train_AMT_2d.shape))\n",
    "print('Adaptive mean testing shape:  {0}'.format(test_AMT_2d.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Adaptive Gaussian Threshold Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive Gaussian training shape: (7326, 640)\n",
      "Adaptive Gaussian testing shape:  (2603, 640)\n"
     ]
    }
   ],
   "source": [
    "train_AGT_2d = np.load('{0}/train_AGT_2d.dat'.format(directory))\n",
    "test_AGT_2d = np.load('{0}/test_AGT_2d.dat'.format(directory))\n",
    "print('Adaptive Gaussian training shape: {0}'.format(train_AGT_2d.shape))\n",
    "print('Adaptive Gaussian testing shape:  {0}'.format(test_AGT_2d.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Principle Component Analysis Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA training shape: (7326, 40)\n",
      "PCA testing shape:  (2603, 40)\n"
     ]
    }
   ],
   "source": [
    "train_PCA_2d = np.load('{0}/train_PCA_2d.dat'.format(directory))\n",
    "test_PCA_2d = np.load('{0}/test_PCA_2d.dat'.format(directory))\n",
    "print('PCA training shape: {0}'.format(train_PCA_2d.shape))\n",
    "print('PCA testing shape:  {0}'.format(test_PCA_2d.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lists of Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = ['Cust', 'OBT', 'AMT', 'AGT', 'PCA']\n",
    "l_train = [train_CustGray_2d, train_OBT_2d, train_AMT_2d, train_AGT_2d, train_PCA_2d]\n",
    "l_test = [test_CustGray_2d, test_OBT_2d, test_AMT_2d, test_AGT_2d, test_PCA_2d]\n",
    "overall_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Important Pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def important_pixels(mdl, ht, wd, save_f):\n",
    "    '''\n",
    "    source: http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances_faces.html#example-ensemble-plot-forest-importances-faces-py\n",
    "    '''\n",
    "    importances = mdl.feature_importances_\n",
    "    importances = importances.reshape(ht,wd)\n",
    "\n",
    "    # Plot pixel importances\n",
    "    plt.matshow(importances, cmap=plt.cm.hot)\n",
    "    plt.savefig(save_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Attributes\n",
    "# estimators_ : list of classifiers\n",
    "# classes_ : array of shape = [n_classes]\n",
    "# n_classes_ : int\n",
    "# estimator_weights_ : array of floats\n",
    "# estimator_errors_ : array of floats\n",
    "# feature_importances_ : array of shape = [n_features]\n",
    "\n",
    "ab_dict = {}\n",
    "\n",
    "for i,dataset in enumerate(l_train):\n",
    "    n_estimators=50\n",
    "    ab_clf = AdaBoostClassifier(base_estimator=None, n_estimators=n_estimators, learning_rate=1.0, \n",
    "                                 algorithm='SAMME.R', random_state=None)\n",
    "    scores = cross_val_score(ab_clf, dataset, train_labels)\n",
    "    ab_dict[('ada_boost_{0}'.format(names[i]),n_estimators)] = scores.mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('ada_boost_AGT', 50): 19.601571674291097,\n",
       " ('ada_boost_AMT', 50): 19.901917264897509,\n",
       " ('ada_boost_Cust', 50): 20.760998576551458,\n",
       " ('ada_boost_OBT', 50): 20.48886398197746,\n",
       " ('ada_boost_PCA', 50): 28.022917438729621}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_dict['ada_boost'] = ab_dict\n",
    "ab_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Attributes\n",
    "# base_estimator_ : list of estimators\n",
    "# estimators_ : list of estimators\n",
    "# estimators_samples_ : list of arrays\n",
    "# estimators_features_ : list of arrays\n",
    "# classes_ : array of shape = [n_classes]\n",
    "# n_classes_ : int or list\n",
    "# oob_score_ : float\n",
    "# oob_decision_function_ : array of shape = [n_samples, n_classes]\n",
    "\n",
    "bag_dict = {}\n",
    "\n",
    "for i,dataset in enumerate(l_train):\n",
    "    bag_clf = BaggingClassifier(base_estimator=None, n_estimators=10, max_samples=1.0, max_features=1.0, \n",
    "                                bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False, \n",
    "                                n_jobs=-1, random_state=None, verbose=0)\n",
    "    scores = cross_val_score(bag_clf, dataset, train_labels)\n",
    "    bag_dict['bagging_{0}'.format(names[i])] = scores.mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_AGT': 51.323460316333801,\n",
       " 'bagging_AMT': 56.659094020191304,\n",
       " 'bagging_Cust': 45.304261573046027,\n",
       " 'bagging_OBT': 59.773823683722483,\n",
       " 'bagging_PCA': 45.835940750864538}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_dict['bagging'] = bag_dict\n",
    "bag_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier - TAKES A LONG TIME TO RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Attributes\n",
    "# feature_importances_ : array, shape = [n_features]\n",
    "# oob_improvement_ : array, shape = [n_estimators]\n",
    "# train_score_ : array, shape = [n_estimators]\n",
    "# loss_ : LossFunction\n",
    "# init : BaseEstimator\n",
    "# estimators_ : ndarray of DecisionTreeRegressor, shape = [n_estimators, loss_.K]\n",
    "    \n",
    "gb_dict = {}\n",
    "\n",
    "for i,dataset in enumerate(l_train):\n",
    "    n_estimators=100\n",
    "    gb_clf = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=n_estimators, subsample=1.0, \n",
    "                                     min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                                     max_depth=3, init=None, random_state=None, max_features=None, verbose=0, \n",
    "                                     max_leaf_nodes=None, warm_start=False, presort='auto')\n",
    "    scores = cross_val_score(gb_clf, dataset, train_labels)\n",
    "    gb_dict[('gradient_boost_{0}'.format(names[i]),n_estimators)] = scores.mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('gradient_boost_AGT', 100): 66.214155600971665,\n",
       " ('gradient_boost_AMT', 100): 69.832856602220886,\n",
       " ('gradient_boost_Cust', 100): 48.690551162692316,\n",
       " ('gradient_boost_OBT', 100): 65.874941537370447,\n",
       " ('gradient_boost_PCA', 100): 51.760066581269207}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_dict['gradient_boost'] = gb_dict\n",
    "gb_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# classes_ : array of shape = [n_classes] or a list of such arrays\n",
    "# feature_importances_ : array of shape = [n_features]\n",
    "# max_features_ : int,\n",
    "# n_classes_ : int or list\n",
    "# n_features_ : int\n",
    "# n_outputs_ : int\n",
    "# tree_ : Tree object\n",
    "\n",
    "dtr_dict = {}\n",
    "\n",
    "for i,dataset in enumerate(l_train):\n",
    "    dtr_clf = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, \n",
    "                            min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, \n",
    "                            max_leaf_nodes=None, class_weight=None, presort=False)\n",
    "\n",
    "    scores = cross_val_score(dtr_clf, dataset, train_labels)\n",
    "    dtr_dict['decision_tree_{0}'.format(names[i])] = scores.mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decision_tree_AGT': 36.144703900143284,\n",
       " 'decision_tree_AMT': 40.171028268996253,\n",
       " 'decision_tree_Cust': 32.570295247530275,\n",
       " 'decision_tree_OBT': 45.412963166240502,\n",
       " 'decision_tree_PCA': 33.170064779635595}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_dict['decision_tree'] = dtr_dict\n",
    "dtr_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "etr_dict = {}\n",
    "\n",
    "for i,dataset in enumerate(l_train):\n",
    "    \n",
    "    etr_clf = ExtraTreesClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2, \n",
    "                    min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, \n",
    "                    bootstrap=False, oob_score=False, n_jobs=-1, random_state=None, verbose=0, warm_start=False, \n",
    "                    class_weight=None)\n",
    "\n",
    "    scores = cross_val_score(etr_clf, dataset, train_labels)\n",
    "    etr_dict['extra_trees_{0}'.format(names[i])] = scores.mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'extra_trees_AGT': 51.555399075043461,\n",
       " 'extra_trees_AMT': 57.69721530246126,\n",
       " 'extra_trees_Cust': 43.993940734755469,\n",
       " 'extra_trees_OBT': 60.046629152872391,\n",
       " 'extra_trees_PCA': 38.710884891591277}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_dict['extra_trees'] = etr_dict\n",
    "etr_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Attributes\n",
    "# estimators_ : list of DecisionTreeClassifier\n",
    "# classes_ : array of shape = [n_classes] or a list of such arrays\n",
    "# n_classes_ : int or list\n",
    "# n_features_ : int\n",
    "# n_outputs_ : int\n",
    "# feature_importances_ : array of shape = [n_features]\n",
    "# oob_score_ : float\n",
    "# oob_decision_function_ : array of shape = [n_samples, n_classes]\n",
    "    \n",
    "rf_dict = {}\n",
    "\n",
    "for i,dataset in enumerate(l_train):\n",
    "    rf_clf = RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2, \n",
    "                                min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', \n",
    "                                max_leaf_nodes=None, bootstrap=True, oob_score=False, n_jobs=-1, random_state=None, \n",
    "                                verbose=0, warm_start=False, class_weight=None)\n",
    "    \n",
    "    scores = cross_val_score(rf_clf, dataset, train_labels)\n",
    "    rf_dict['random_forrest_{0}'.format(names[i])] = scores.mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_forrest_AGT': 48.169410711487778,\n",
       " 'random_forrest_AMT': 54.16189218059845,\n",
       " 'random_forrest_Cust': 42.478717979674528,\n",
       " 'random_forrest_OBT': 56.975636870828282,\n",
       " 'random_forrest_PCA': 42.274185093343}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_dict['random_forrest'] = rf_dict\n",
    "rf_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "    \n",
    "knn_dict = {}\n",
    "\n",
    "for i,dataset in enumerate(l_train):\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, \n",
    "                                   metric='minkowski', metric_params=None, n_jobs=-1)\n",
    "    \n",
    "    scores = cross_val_score(knn_clf, dataset, train_labels)\n",
    "    knn_dict['kneighbors_{0}'.format(names[i])] = scores.mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kneighbors_AGT': 60.278115454419712,\n",
       " 'kneighbors_AMT': 63.771514237182359,\n",
       " 'kneighbors_Cust': 44.868008839839568,\n",
       " 'kneighbors_OBT': 56.469231326074706,\n",
       " 'kneighbors_PCA': 61.575175530410156}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_dict['kneighbors'] = knn_dict\n",
    "knn_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_dict = {}\n",
    "\n",
    "for i,dataset in enumerate(l_train):\n",
    "    svc_clf = SVC(C=1.0, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, probability=False, \n",
    "                  tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, \n",
    "                  decision_function_shape=None)\n",
    "    \n",
    "    scores = cross_val_score(svc_clf, dataset, train_labels)\n",
    "    svc_dict['svc_{0}'.format(names[i])] = scores.mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc_AGT': 19.178291874734157,\n",
       " 'svc_AMT': 19.178291874734157,\n",
       " 'svc_Cust': 19.178291874734157,\n",
       " 'svc_OBT': 19.178291874734157,\n",
       " 'svc_PCA': 65.969377416059118}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_dict['svc'] = svc_dict\n",
    "svc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "logr_dict = {}\n",
    "\n",
    "for i,dataset in enumerate(l_train):\n",
    "    logr_clf = SGDClassifier(loss='hinge', penalty='l2', alpha=0.0001, l1_ratio=0.15, fit_intercept=True, n_iter=5, \n",
    "                             shuffle=True, verbose=0, epsilon=0.1, n_jobs=-1, random_state=None, learning_rate='optimal', \n",
    "                             eta0=0.0, power_t=0.5, class_weight=None, warm_start=False, average=False)\n",
    "    \n",
    "    scores = cross_val_score(logr_clf, dataset, train_labels)\n",
    "    logr_dict['log_regression_{0}'.format(names[i])] = scores.mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'log_regression_AGT': 14.388400391727888,\n",
       " 'log_regression_AMT': 16.492265762796006,\n",
       " 'log_regression_Cust': 11.657378081433167,\n",
       " 'log_regression_OBT': 13.32386553347723,\n",
       " 'log_regression_PCA': 13.936506725298178}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_dict['log_regression'] = logr_dict\n",
    "logr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bagging_AGT': 51.323460316333801,\n",
       "  'bagging_AMT': 56.659094020191304,\n",
       "  'bagging_Cust': 45.304261573046027,\n",
       "  'bagging_OBT': 59.773823683722483,\n",
       "  'bagging_PCA': 45.835940750864538},\n",
       " {'kneighbors_AGT': 60.278115454419712,\n",
       "  'kneighbors_AMT': 63.771514237182359,\n",
       "  'kneighbors_Cust': 44.868008839839568,\n",
       "  'kneighbors_OBT': 56.469231326074706,\n",
       "  'kneighbors_PCA': 61.575175530410156},\n",
       " {'decision_tree_AGT': 36.144703900143284,\n",
       "  'decision_tree_AMT': 40.171028268996253,\n",
       "  'decision_tree_Cust': 32.570295247530275,\n",
       "  'decision_tree_OBT': 45.412963166240502,\n",
       "  'decision_tree_PCA': 33.170064779635595},\n",
       " {('ada_boost_AGT', 50): 19.601571674291097,\n",
       "  ('ada_boost_AMT', 50): 19.901917264897509,\n",
       "  ('ada_boost_Cust', 50): 20.760998576551458,\n",
       "  ('ada_boost_OBT', 50): 20.48886398197746,\n",
       "  ('ada_boost_PCA', 50): 28.022917438729621},\n",
       " {'random_forrest_AGT': 48.169410711487778,\n",
       "  'random_forrest_AMT': 54.16189218059845,\n",
       "  'random_forrest_Cust': 42.478717979674528,\n",
       "  'random_forrest_OBT': 56.975636870828282,\n",
       "  'random_forrest_PCA': 42.274185093343},\n",
       " {'log_regression_AGT': 14.388400391727888,\n",
       "  'log_regression_AMT': 16.492265762796006,\n",
       "  'log_regression_Cust': 11.657378081433167,\n",
       "  'log_regression_OBT': 13.32386553347723,\n",
       "  'log_regression_PCA': 13.936506725298178},\n",
       " {('gradient_boost_AGT', 100): 66.214155600971665,\n",
       "  ('gradient_boost_AMT', 100): 69.832856602220886,\n",
       "  ('gradient_boost_Cust', 100): 48.690551162692316,\n",
       "  ('gradient_boost_OBT', 100): 65.874941537370447,\n",
       "  ('gradient_boost_PCA', 100): 51.760066581269207},\n",
       " {'svc_AGT': 19.178291874734157,\n",
       "  'svc_AMT': 19.178291874734157,\n",
       "  'svc_Cust': 19.178291874734157,\n",
       "  'svc_OBT': 19.178291874734157,\n",
       "  'svc_PCA': 65.969377416059118},\n",
       " {'extra_trees_AGT': 51.555399075043461,\n",
       "  'extra_trees_AMT': 57.69721530246126,\n",
       "  'extra_trees_Cust': 43.993940734755469,\n",
       "  'extra_trees_OBT': 60.046629152872391,\n",
       "  'extra_trees_PCA': 38.710884891591277}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(overall_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-4e5966738ca1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moverall_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moverall_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mlst_cnts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "mdls = [k for k,v in overall_dict.items()]\n",
    "lst_cnts = []\n",
    "for k,v in overall_dict.items():\n",
    "    temp = []\n",
    "    for x,y in overall_dict[v].values():\n",
    "        temp.append(y)\n",
    "    lst_cnts.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind = range(1,6)  # the x locations for the groups\n",
    "width = 0.35       # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(ind, menMeans, width, color='r', yerr=menStd)\n",
    "\n",
    "\n",
    "rects2 = ax.bar(ind + width, womenMeans, width, color='y', yerr=womenStd)\n",
    "\n",
    "# add some text for labels, title and axes ticks\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Scores by group and gender')\n",
    "ax.set_xticks(ind + width)\n",
    "ax.set_xticklabels(('G1', 'G2', 'G3', 'G4', 'G5'))\n",
    "\n",
    "ax.legend((rects1[0], rects2[0]), ('Men', 'Women'))\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "    # attach some text labels\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n",
    "                '%d' % int(height),\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make figure\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# plots\n",
    "plt.bar(range(len(train_cnt_dict)), train_cnt_dict.values(), , color=colors[5], \n",
    "                alpha=0.5, edgecolor='w', label='Training Labels')\n",
    "\n",
    "# labels/titles\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('Class Labels')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency Distribution of Class Labels')\n",
    "\n",
    "plt.xlim(-0.5,9.5)\n",
    "ticks = [0,1,2,3,4,5,6,7,8,9]\n",
    "plt.xticks(ticks, ticks)\n",
    "\n",
    "# remove border\n",
    "ax.spines[\"top\"].set_visible(False)  \n",
    "ax.spines[\"right\"].set_visible(False) \n",
    "ax.spines[\"bottom\"].set_visible(False) \n",
    "ax.spines[\"left\"].set_visible(False)\n",
    "\n",
    "# show grid\n",
    "ax.yaxis.grid(True) \n",
    "\n",
    "# plot that biddy\n",
    "plt.tight_layout()\n",
    "_ = plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
