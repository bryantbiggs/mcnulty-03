{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request \n",
    "import operator\n",
    "from collections import Counter\n",
    "\n",
    "### USE OpenCV KERNEL ###\n",
    "#import cv2\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "    \n",
    "# default plot stying changes\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"poster\", font_scale=1.25, rc={\"lines.linewidth\": 2.5})\n",
    "sns.set_palette(\"Set2\")\n",
    "colors = sns.color_palette('Set2',12)\n",
    "\n",
    "# ignore decpricated warnings, etc.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.tools import FigureFactory as FF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotly username and password\n",
    "with open('../_credentials/plotly.txt', 'r') as infile:\n",
    "    user, pw = infile.read().strip().split(', ')\n",
    "    \n",
    "plotly.tools.set_credentials_file(username=user, api_key=pw)\n",
    "\n",
    "text_color = 'rgb(107, 107, 107)'\n",
    "\n",
    "colors_dict = {'grey':'rgb(189, 195, 199)', 'aqua':'rgb( 54, 215, 183)', 'navy':'rgb( 31,  58, 147)',\n",
    "            'purple':'rgb(142,  68, 173)', 'blue':'rgb( 25, 181, 254)', 'green':'rgb( 46, 204, 113)',\n",
    "            'yellow':'rgb(253, 231,  76)', 'orange':'rgb(250, 121,  33)', 'red':'rgb(242,  38,  19)'}\n",
    "\n",
    "colors_lst = [colors_dict['yellow'], colors_dict['orange'], colors_dict['red'], \n",
    "              colors_dict['green'], colors_dict['blue'], colors_dict['purple'], \n",
    "              colors_dict['navy'], colors_dict['aqua'], colors_dict['grey']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_datasets():\n",
    "    # if output directory doesn't exist, make it\n",
    "    raw_dir = 'data/raw_data'\n",
    "    \n",
    "    if not os.path.exists(raw_dir):\n",
    "        os.makedirs(raw_dir)\n",
    "\n",
    "    # base url and filenames for data sets from Stanford\n",
    "    base_url = 'http://ufldl.stanford.edu/housenumbers/'\n",
    "    train_file = 'train_32x32.mat'\n",
    "    test_file = 'test_32x32.mat'\n",
    "    extra_file = 'extra_32x32.mat'\n",
    "\n",
    "    files = [train_file, test_file, extra_file]\n",
    "\n",
    "    # download files if they do not exist\n",
    "    for file in files:\n",
    "        if not os.path.isfile('{0}/{1}'.format(raw_dir, file)):\n",
    "            _ = urllib.request.urlretrieve('{0}/{1}'.format(base_url, file), '{0}/{1}'.format(raw_dir, file))\n",
    "        if os.path.isfile('{0}/{1}'.format(raw_dir, file)):\n",
    "            print('Downloaded: {0}'.format(file))\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: train_32x32.mat\n",
      "Downloaded: test_32x32.mat\n",
      "Downloaded: extra_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "get_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Raw Data (.mat Files) into Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(lim=0.1, _set='train', raw_dir='data/raw_data'):\n",
    "    if (float(lim) <= 1.0) & (float(lim) > 0.0):\n",
    "        \n",
    "        # limit number of data points\n",
    "        lim_train = round(73257*lim)\n",
    "        lim_test = round(26032*lim)\n",
    "        lim_extra = round(531131*lim)\n",
    "\n",
    "        if _set=='train':\n",
    "            train_data = loadmat(raw_dir+'/train_32x32.mat', variable_names='X').get('X')[:,:,:,:lim_train]\n",
    "            train_labels = loadmat(raw_dir+'/train_32x32.mat', variable_names='y').get('y')[:lim_train]\n",
    "            return train_data, train_labels\n",
    "        \n",
    "        if _set=='test':\n",
    "            test_data = loadmat(raw_dir+'/test_32x32.mat', variable_names='X').get('X')[:,:,:,:lim_test]\n",
    "            test_labels = loadmat(raw_dir+'/test_32x32.mat', variable_names='y').get('y')[:lim_test]\n",
    "            return test_data, test_labels\n",
    "        \n",
    "        if _set=='extra':\n",
    "            extra_data = loadmat(raw_dir+'/extra_32x32.mat', variable_names='X').get('X')[:,:,:,:lim_extra]\n",
    "            extra_labels = loadmat(raw_dir+'/extra_32x32.mat', variable_names='y').get('y')[:lim_extra]\n",
    "            return extra_data, extra_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data, train_labels = load_data(lim=0.1, _set='train')\n",
    "test_data, test_labels = load_data(lim=0.1, _set='test')\n",
    "extra_data, extra_labels = load_data(lim=0.05, _set='extra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (32, 32, 3, 7326) | Training labels shape: (7326, 1)\n",
      "Testing data shape: (32, 32, 3, 2603) | Testing labels shape: (2603, 1)\n",
      "Extra data shape: (32, 32, 3, 26557) | Extra labels shape: (26557, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape: {0} | Training labels shape: {1}'.format(train_data.shape, train_labels.shape))\n",
    "print('Testing data shape: {0} | Testing labels shape: {1}'.format(test_data.shape, test_labels.shape))\n",
    "print('Extra data shape: {0} | Extra labels shape: {1}'.format(extra_data.shape, extra_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of Labels in Test and Train Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert 10's to 0's\n",
    "train_labels[train_labels == 10] = 0\n",
    "test_labels[test_labels == 10] = 0\n",
    "extra_labels[extra_labels == 10] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make dictionary of label counts\n",
    "train_lbl_lst = np.ravel(train_labels).tolist()\n",
    "train_cnt_dict = dict(Counter(train_lbl_lst))\n",
    "\n",
    "test_lbl_lst = np.ravel(test_labels).tolist()\n",
    "test_cnt_dict = dict(Counter(test_lbl_lst))\n",
    "\n",
    "extra_lbl_lst = np.ravel(extra_labels).tolist()\n",
    "extra_cnt_dict = dict(Counter(extra_lbl_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_bar_trace(x_labels, y_counts, _set, clr):\n",
    "    trace = go.Bar(\n",
    "        x = x_labels, \n",
    "        y = y_counts, \n",
    "        name = _set, \n",
    "        marker=dict(color=clr), \n",
    "        opacity=0.8\n",
    "        )\n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traces = []\n",
    "lst_dataset_dicts = [('Test', test_cnt_dict), ('Train',train_cnt_dict), ('Extra',extra_cnt_dict)]\n",
    "\n",
    "for i, dataset_dict in enumerate(lst_dataset_dicts):\n",
    "    traces.append(make_bar_trace(list(dataset_dict[1].keys()), \n",
    "                                 list(dataset_dict[1].values()), \n",
    "                                 dataset_dict[0], \n",
    "                                 colors_lst[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~bbiggs/219.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = traces\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Frequency Distribution of Class Labels',\n",
    "    xaxis=dict(\n",
    "        title='Class Labels',\n",
    "        tickfont=dict(size=14, color='rgb(107, 107, 107)'),\n",
    "        dtick=1\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Frequency',\n",
    "        titlefont=dict(size=16, color='rgb(107, 107, 107)'),\n",
    "        tickfont=dict(size=14, color='rgb(107, 107, 107)'),\n",
    "    ),\n",
    "    barmode='stack',)\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='SVHN Label Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = train_data.transpose((3,0,1,2))\n",
    "test_data = test_data.transpose((3,0,1,2))\n",
    "#extra_data = extra_data.transpose((3,0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = np.ravel(train_labels)\n",
    "test_labels = np.ravel(test_labels)\n",
    "#extra_labels = np.ravel(extra_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Training data shape: {0} | Training labels shape: {1}'.format(train_data.shape, train_labels.shape))\n",
    "print('Testing data shape:  {0}  | Testing labels shape:  {1}'.format(test_data.shape, test_labels.shape))\n",
    "#print('Extra data shape:    {0}     | Extra labels shape:    {1}'.format(extra_data.shape, extra_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at One Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_img = train_data[:,:,:,:][0]\n",
    "one_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "fig.set_size_inches(3, 3)\n",
    "plt.xticks([]),plt.yticks([])\n",
    "_ = plt.imshow(one_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Conversion with Limited Number of Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gray_conv(image, num_shades):\n",
    "    '''\n",
    "    input: image array(h,w), and number of desired gray shades\n",
    "    output: list of converted rgb values\n",
    "    '''\n",
    "    if num_shades < 255 or num_shades > 2:\n",
    "        x, y, _ = image.shape\n",
    "        gray = []\n",
    "        \n",
    "        for i in range(x):\n",
    "            for j in range(y):\n",
    "                conv = 255 / (num_shades - 1)\n",
    "                avg = (sum(image[i][j])) / 3\n",
    "                gray.append(int(int(round(avg / conv)) * conv))\n",
    "    return np.array(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_arr_conv(lst,row,col):\n",
    "    '''\n",
    "    ONLY NEEDED FOR VIEWING IMAGES - NOT ANALYSIS\n",
    "    input: list with desired image height(row) and width(col)\n",
    "    output: image in the form of ndarray(col,row)\n",
    "    '''\n",
    "    result = np.array(lst)\n",
    "    result = np.ndarray.reshape(result, (row,col))\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_CustGray_2d_arr(img_arr, col_l, col_r, num_shades):\n",
    "    '''\n",
    "    input: array of images as ndarray, left col start and right col end for image slicing\n",
    "            and number of gray shade limit\n",
    "    output: ndarray of ndarrays (images, pixels) with limited number of greyscale values\n",
    "    '''\n",
    "    num_imgs, _, _, _ = img_arr.shape\n",
    "    \n",
    "    arr_2d = []\n",
    "    \n",
    "    for i in range(num_imgs):\n",
    "        img = img_arr[:,:,:,:][i]\n",
    "        img_trim = img[:, col_l:col_r]\n",
    "        \n",
    "        gray_img = gray_conv(img_trim, num_shades)\n",
    "        \n",
    "        arr_2d.append(gray_img)\n",
    "    \n",
    "    return np.asarray(arr_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of Custom Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_num = 5\n",
    "shades = 32\n",
    "\n",
    "orig_img = train_data[:,:,:,:][img_num]\n",
    "orig_img = orig_img[:,6:26]\n",
    "scaled_img = img_arr_conv(gray_conv(orig_img, shades), 32, 20)\n",
    "\n",
    "titles = ['Original', 'Custom Conversion']\n",
    "images = [orig_img, scaled_img]\n",
    "\n",
    "fig.set_size_inches(3, 3)\n",
    "for i in range(2):\n",
    "    plt.subplot(1,2,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.axis('off')\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "select_img = 7\n",
    "block_sz = 7\n",
    "const = 2 # subtracted from the mean or weighted mean calculated\n",
    "\n",
    "# original image\n",
    "img = train_data[:,:,:,:][select_img]\n",
    "img = img[:,6:26]\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Otsus Binariziation \n",
    "blur = cv2.GaussianBlur(img,(5,5),0)\n",
    "ret, th1 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# Adaptive mean\n",
    "th2 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, block_sz, const)\n",
    "\n",
    "# Adaptive Gaussian\n",
    "th3 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, block_sz, const)\n",
    "\n",
    "titles = ['Gray Orig.', 'Otsu\\'s Binarization', 'Adpt. Mean', 'Adpt. Gaussian']\n",
    "images = [img, th1, th2, th3]\n",
    "\n",
    "fig.set_size_inches(12, 6)\n",
    "for i in range(4):\n",
    "    \n",
    "    plt.subplot(1,4,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.axis('off')\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(th3,'gray')\n",
    "plt.axis('off')\n",
    "plt.xticks([]),plt.yticks([])\n",
    "plt.savefig('imgs/agt_7.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otsu's Binarization Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_OBT_2d_arr(img_arr, col_l, col_r, block_size):\n",
    "    '''\n",
    "    input: array of images as ndarray, left col start and right col end for image slicing\n",
    "    output: ndarray of ndarrays (images, pixels) thresholded using Otsu's binarization thresholding\n",
    "    source: http://docs.opencv.org/trunk/d7/d4d/tutorial_py_thresholding.html#gsc.tab=0\n",
    "    '''\n",
    "    num_imgs, _, _, _ = img_arr.shape\n",
    "    \n",
    "    arr_2d = []\n",
    "    \n",
    "    for i in range(num_imgs):\n",
    "        # grab individual image\n",
    "        img = img_arr[:,:,:,:][i]\n",
    "        \n",
    "        # convert to grayscale\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        # trim width (focus on digit)\n",
    "        img = img[:, col_l:col_r]\n",
    "        \n",
    "        # make sure the blur block size is odd\n",
    "        if block_size % 2 == 0:\n",
    "            block_size += 1\n",
    "            \n",
    "        # Otsus Binariziation\n",
    "        blur = cv2.GaussianBlur(img,(block_size,block_size),0)\n",
    "            \n",
    "        _, img = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        \n",
    "        arr_2d.append(np.ravel(img))\n",
    "    \n",
    "    return np.asarray(arr_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Mean Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_AMT_2d_arr(img_arr, col_l, col_r, block_size, const):\n",
    "    '''\n",
    "    input: array of images as ndarray, left col start and right col end for image slicing\n",
    "    output: ndarray of ndarrays (images, pixels) thresholded using adaptive mean\n",
    "    source: http://docs.opencv.org/trunk/d7/d4d/tutorial_py_thresholding.html#gsc.tab=0\n",
    "    '''\n",
    "    num_imgs, _, _, _ = img_arr.shape\n",
    "    \n",
    "    arr_2d = []\n",
    "    \n",
    "    for i in range(num_imgs):\n",
    "        # grab individual image\n",
    "        img = img_arr[:,:,:,:][i]\n",
    "        \n",
    "        # convert to grayscale\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        # trim width (focus on digit)\n",
    "        img = img[:, col_l:col_r]\n",
    "        \n",
    "        # make sure the blur block size is odd\n",
    "        if block_size % 2 == 0:\n",
    "            block_size += 1\n",
    "            \n",
    "        # Adaptive mean\n",
    "        img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, block_size, const)\n",
    "        \n",
    "        arr_2d.append(np.ravel(img))\n",
    "    \n",
    "    return np.asarray(arr_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Gausian Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_AGT_2d_arr(img_arr, col_l, col_r, block_size, const):\n",
    "    '''\n",
    "    input: array of images as ndarray, left col start and right col end for image slicing\n",
    "    output: ndarray of ndarrays (images, pixels) thresholded using adaptive Gausian\n",
    "    source: http://docs.opencv.org/trunk/d7/d4d/tutorial_py_thresholding.html#gsc.tab=0\n",
    "    '''\n",
    "    num_imgs, _, _, _ = img_arr.shape\n",
    "    \n",
    "    arr_2d = []\n",
    "    \n",
    "    for i in range(num_imgs):\n",
    "        # grab individual image\n",
    "        img = img_arr[:,:,:,:][i]\n",
    "        \n",
    "        # convert to grayscale\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        # trim width (focus on digit)\n",
    "        img = img[:, col_l:col_r]\n",
    "        \n",
    "        # make sure the blur block size is odd\n",
    "        if block_size % 2 == 0:\n",
    "            block_size += 1\n",
    "            \n",
    "        # Adaptive Gaussian\n",
    "        img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, block_size, const)\n",
    "        \n",
    "        arr_2d.append(np.ravel(img))\n",
    "    \n",
    "    return np.asarray(arr_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_PCA_2d_arr(img_arr, col_l, col_r, numb_components):\n",
    "    '''\n",
    "    input: array of images as ndarray, left col start and right col end for image slicing and number of components\n",
    "    output: ndarray of ndarrays (images, pixels) flattened using PCA to limited number of colors\n",
    "    source: https://medium.com/@dimart/pok%C3%A9mon-recognition-d3ad5cadc61e#.whsqst6us\n",
    "    '''\n",
    "    num_imgs, _, _, _ = img_arr.shape\n",
    "    \n",
    "    arr_2d = []\n",
    "    \n",
    "    for i in range(num_imgs):\n",
    "        # grab individual image\n",
    "        img = img_arr[:,:,:,:][i]\n",
    "        \n",
    "        # convert to grayscale\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        # trim width (focus on digit)\n",
    "        img = img[:, col_l:col_r]\n",
    "        \n",
    "        arr_2d.append(np.ravel(img))\n",
    "    \n",
    "    # converted images into 2d grayscale\n",
    "    arr_2d = np.asarray(arr_2d)\n",
    "    \n",
    "    # apply principal component analysis\n",
    "    pca = PCA(n_components=numb_components, whiten=True).fit(arr_2d)\n",
    "    pca_arr = pca.transform(arr_2d)\n",
    "    \n",
    "    return pca_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle Numpy Arrays (Output Processed Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if output directory doesn't exist, make it\n",
    "output_directory = 'generated_data'\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Conversion Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl, cr = 6, 26\n",
    "ns = 7 # number of shades\n",
    "\n",
    "train_f = 'train_CustGray_2d.dat'\n",
    "test_f = 'test_CustGray_2d.dat'\n",
    "\n",
    "# remove existing files if they exist\n",
    "try:\n",
    "    os.remove(train_f)\n",
    "    os.remove(test_f)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "train_CustGray_arr = conv_CustGray_2d_arr(train_data, col_l=cl, col_r=cr, num_shades=ns)\n",
    "train_CustGray_arr.dump('{0}/{1}'.format(output_directory, train_f))\n",
    "              \n",
    "test_CustGray_arr = conv_CustGray_2d_arr(test_data, col_l=cl, col_r=cr, num_shades=ns)\n",
    "test_CustGray_arr.dump('{0}/{1}'.format(output_directory, test_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(train_CustGray_arr.shape)\n",
    "print(test_CustGray_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otsu's Binarization Thresholding Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl, cr = 6, 26\n",
    "bs = 7 # block size\n",
    "\n",
    "train_f = 'train_OBT_2d.dat'\n",
    "test_f = 'test_OBT_2d.dat'\n",
    "\n",
    "# remove existing files if they exist\n",
    "try:\n",
    "    os.remove(train_f)\n",
    "    os.remove(test_f)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "train_OBT_arr = conv_OBT_2d_arr(train_data, col_l=cl, col_r=cr, block_size=bs)\n",
    "train_OBT_arr.dump('{0}/{1}'.format(output_directory, train_f))\n",
    "\n",
    "test_OBT_arr = conv_OBT_2d_arr(test_data, col_l=cl, col_r=cr, block_size=bs)\n",
    "test_OBT_arr.dump('{0}/{1}'.format(output_directory, test_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(train_OBT_arr.shape)\n",
    "print(test_OBT_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Mean Thresholding Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl, cr = 6, 26\n",
    "bs = 7 # block size\n",
    "c = 2 # constant\n",
    "\n",
    "train_f = 'train_AMT_2d.dat'\n",
    "test_f = 'test_AMT_2d.dat'\n",
    "\n",
    "# remove existing files if they exist\n",
    "try:\n",
    "    os.remove(train_f)\n",
    "    os.remove(test_f)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "train_AMT_arr = conv_AMT_2d_arr(train_data, col_l=cl, col_r=cr, block_size=bs, const=c)\n",
    "train_AMT_arr.dump('{0}/{1}'.format(output_directory, train_f))\n",
    "\n",
    "test_AMT_arr = conv_AMT_2d_arr(test_data, col_l=cl, col_r=cr, block_size=bs, const=c)\n",
    "test_AMT_arr.dump('{0}/{1}'.format(output_directory, test_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(train_AMT_arr.shape)\n",
    "print(test_AMT_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Gaussian Thresholding Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl, cr = 6, 26\n",
    "bs = 7 # block size\n",
    "c = 2 # constant\n",
    "\n",
    "train_f = 'train_AGT_2d.dat'\n",
    "test_f = 'test_AGT_2d.dat'\n",
    "\n",
    "# remove existing files if they exist\n",
    "try:\n",
    "    os.remove(train_f)\n",
    "    os.remove(test_f)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "train_AGT_arr = conv_AGT_2d_arr(train_data, col_l=cl, col_r=cr, block_size=bs, const=c)\n",
    "train_AGT_arr.dump('{0}/{1}'.format(output_directory, train_f))\n",
    "\n",
    "test_AGT_arr = conv_AGT_2d_arr(test_data, col_l=cl, col_r=cr, block_size=bs, const=c)\n",
    "test_AGT_arr.dump('{0}/{1}'.format(output_directory, test_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train_AGT_arr.shape)\n",
    "print(test_AGT_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principle Component Analysis Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl, cr = 6, 26\n",
    "nc = 40 # number of components\n",
    "\n",
    "train_f = 'train_PCA_2d.dat'\n",
    "test_f = 'test_PCA_2d.dat'\n",
    "\n",
    "# remove existing files if they exist\n",
    "try:\n",
    "    os.remove(train_f)\n",
    "    os.remove(test_f)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "train_PCA_arr = conv_PCA_2d_arr(train_data, col_l=cl, col_r=cr, numb_components=nc)\n",
    "train_PCA_arr.dump('{0}/{1}'.format(output_directory, train_f))\n",
    "\n",
    "test_PCA_arr = conv_PCA_2d_arr(test_data, col_l=cl, col_r=cr, numb_components=nc)\n",
    "test_PCA_arr.dump('{0}/{1}'.format(output_directory, test_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(train_PCA_arr.shape)\n",
    "print(test_PCA_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pickle_labels(arr, directory, filename):\n",
    "    arr.dump('{0}/{1}'.format(directory,filename))\n",
    "\n",
    "train_f = 'train_labels.dat'\n",
    "test_f = 'test_labels.dat'\n",
    "\n",
    "# remove existing files if they exist\n",
    "try:\n",
    "    os.remove(train_f)\n",
    "    os.remove(test_f)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "# output to pickle files\n",
    "pickle_labels(train_labels, output_directory, train_f)\n",
    "pickle_labels(test_labels, output_directory, test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp = []\n",
    "for i in range(1000):\n",
    "    orig_img = train_data[:,:,:,:][i]\n",
    "    scaled_img = img_arr_conv(gray_conv(orig_img, 255), 32, 32)\n",
    "    scaled_img = scaled_img[:,6:26]\n",
    "    exp.append(scaled_img)\n",
    "\n",
    "exp = np.asarray(exp)\n",
    "exp = np.ndarray.reshape(exp, (1000,640))\n",
    "exp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply PCA\n",
    "h, w = 32, 20\n",
    "n_components = 200\n",
    "\n",
    "pca = PCA(n_components=n_components, whiten=True).fit(exp)\n",
    "train_pca = pca.transform(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "reconstruction = pca.inverse_transform(train_pca[7])\n",
    "im = Image.fromarray(reconstruction.reshape(h,w))\n",
    "\n",
    "plt.imshow(im, cmap='Greys_r')\n",
    "plt.axis('off')\n",
    "_ = plt.show\n",
    "\n",
    "plt.imshow(im,'gray')\n",
    "plt.axis('off')\n",
    "plt.xticks([]),plt.yticks([])\n",
    "plt.savefig('imgs/pca_7.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
