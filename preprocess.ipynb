{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "### USE OpenCV KERNEL ###\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in .mat Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'original_data/train_32x32.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6e86abc6b059>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlim_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'original_data/train_32x32.mat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlim_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'original_data/train_32x32.mat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlim_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/envs/opencv_env/lib/python3.5/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \"\"\"\n\u001b[1;32m    134\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mMR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmdict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/envs/opencv_env/lib/python3.5/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mmat_reader_factory\u001b[0;34m(file_name, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m        \u001b[0mtype\u001b[0m \u001b[0mdetected\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \"\"\"\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mbyte_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mmjv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_matfile_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmjv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/envs/opencv_env/lib/python3.5/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'original_data/train_32x32.mat'"
     ]
    }
   ],
   "source": [
    "# limit number of data points\n",
    "lim_train = 1000\n",
    "lim_test = 100\n",
    "\n",
    "train_data = loadmat('original_data/train_32x32.mat', variable_names='X').get('X')[:,:,:,:lim_train]\n",
    "train_labels = loadmat('original_data/train_32x32.mat', variable_names='y').get('y')[:lim_train]\n",
    "\n",
    "test_data = loadmat('original_data/test_32x32.mat', variable_names='X').get('X')[:,:,:,:lim_test]\n",
    "test_labels = loadmat('original_data/test_32x32.mat', variable_names='y').get('y')[:lim_test]\n",
    "\n",
    "#extra_data = loadmat('original_data/extra_32x32.mat', variable_names='X').get('X')[:,:,:,:1]\n",
    "#extra_labels = loadmat('original_data/extra_32x32.mat', variable_names='y').get('y')[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Training data shape: {0} | Training labels shape: {1}'.format(train_data.shape, train_labels.shape))\n",
    "print('Testing data shape:  {0}  | Testing labels shape:  {1}'.format(test_data.shape, test_labels.shape))\n",
    "#print('Extra data shape:    {0}     | Extra labels shape:    {1}'.format(extra_data.shape, extra_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = train_data.transpose((3,0,1,2))\n",
    "test_data = test_data.transpose((3,0,1,2))\n",
    "#extra_data = extra_data.transpose((3,0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = np.ravel(train_labels)\n",
    "test_labels = np.ravel(test_labels)\n",
    "#extra_labels = np.ravel(extra_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Training data shape: {0} | Training labels shape: {1}'.format(train_data.shape, train_labels.shape))\n",
    "print('Testing data shape:  {0}  | Testing labels shape:  {1}'.format(test_data.shape, test_labels.shape))\n",
    "#print('Extra data shape:    {0}     | Extra labels shape:    {1}'.format(extra_data.shape, extra_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at One Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_img = train_data[:,:,:,:][0]\n",
    "one_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(one_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion with Color Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gray_conv(image, num_shades):\n",
    "    '''\n",
    "    input: image array(h,w), and number of desired gray shades\n",
    "    output: list of converted rgb values\n",
    "    '''\n",
    "    if num_shades < 255 or num_shades > 2:\n",
    "        x, y, _ = image.shape\n",
    "        gray = []\n",
    "        \n",
    "        for i in range(x):\n",
    "            for j in range(y):\n",
    "                conv = 255 / (num_shades - 1)\n",
    "                avg = (sum(image[i][j])) / 3\n",
    "                gray.append(int(int(round(avg / conv)) * conv))\n",
    "    return np.array(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_arr_conv(lst,row,col):\n",
    "    '''\n",
    "    ONLY NEEDED FOR VIEWING IMAGES - NOT ANALYSIS\n",
    "    input: list with desired image height(row) and width(col)\n",
    "    output: image in the form of ndarray(col,row)\n",
    "    '''\n",
    "    result = np.array(lst)\n",
    "    result = np.ndarray.reshape(result, (row,col))\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_gray_2d_arr(img_arr, col_left, col_right, num_shades):\n",
    "    '''\n",
    "    input: array of images as ndarray, left col start and right col end for image slicing\n",
    "            and number of gray shade limit\n",
    "    output: ndarray of ndarrays (images, pixels)\n",
    "    '''\n",
    "    num_imgs, _, _, _ = img_arr.shape\n",
    "    \n",
    "    arr_2d = []\n",
    "    \n",
    "    for i in range(num_imgs):\n",
    "        img = img_arr[:,:,:,:][i]\n",
    "        img_trim = img[:, col_left:col_right]\n",
    "        \n",
    "        gray_img = gray_conv(img_trim, num_shades)\n",
    "        \n",
    "        arr_2d.append(gray_img)\n",
    "    \n",
    "    return np.asarray(arr_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Numpy Pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_arr = conv_gray_2d_arr(train_data, col_left=6, col_right=26, num_shades=32)\n",
    "test_arr = conv_gray_2d_arr(test_data, col_left=6, col_right=26, num_shades=32)\n",
    "\n",
    "train_arr.dump('generated_data/train_gray_2d.dat')\n",
    "train_labels.dump('generated_data/train_labels.dat')\n",
    "\n",
    "test_arr.dump('generated_data/test_gray_2d.dat')\n",
    "train_labels.dump('generated_data/train_labels.dat')\n",
    "\n",
    "#conv_gray_2d_arr = numpy.load(\"conv_gray_2d_arr.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(train_arr.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_arr.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_num = 5\n",
    "shades = 32\n",
    "\n",
    "orig_img = train_data[:,:,:,:][img_num]\n",
    "scaled_img = img_arr_conv(gray_conv(orig_img, shades), 32, 32)\n",
    "scaled_img = scaled_img[:,6:26]\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, sharex=True, sharey=True, subplot_kw={'adjustable':'box-forced'})\n",
    "ax0.imshow(scaled_img, cmap='Greys_r')\n",
    "ax0.set_title('Mine')\n",
    "ax0.axis('off')\n",
    "ax1.imshow(orig_img)\n",
    "ax1.set_title('Normal')\n",
    "ax1.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Adaptive Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# retval, thresh = cv2.threshold(a, 4, 255, cv2.THRESH_BINARY)\n",
    "a = train_data[:,:,:,:][5]\n",
    "grayscaled = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "gaus = cv2.adaptiveThreshold(grayscaled, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 15, 1)\n",
    "\n",
    "# trim to number of focus\n",
    "gaus = gaus[:,6:26]\n",
    "\n",
    "plt.imshow(gaus, cmap='Greys_r')\n",
    "plt.axis('off')\n",
    "_ = plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set training labels of 10 equal to 0\n",
    "train_labels[train_labels == 10] = 0\n",
    "test_labels[test_labels == 10] = 0\n",
    "extra_labels[extra_labels == 10] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = test_data.transpose((3,0,1,2))\n",
    "train_labels = np.ravel(train_labels)\n",
    "test_labels = np.ravel(test_labels)\n",
    "print(train_data.shape, train_labels.shape)\n",
    "print(test_data.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_size = 32  # image height and width\n",
    "pixel_depth = 255.0  \n",
    "\n",
    "def im2gray(image):\n",
    "    '''Normalize images'''\n",
    "    image = image.astype(float)\n",
    "    # grayscale conversion per http://www.eyemaginary.com/Rendering/TurnColorsGray.pdf\n",
    "    image_gray = np.dot(image, [[0.2989],[0.5870],[0.1140]])\n",
    "    r = np.dot(image, [[0.2989],[0.5870],[0.1140]])\n",
    "    g = np.dot(image, [[0.5000],[0.5000],[0.1140]])\n",
    "    b = np.dot(image, [[1.0000],[-1.0000],[0.0000]])\n",
    "    return image_gray\n",
    "\n",
    "train_data_c = im2gray(train_data_t)[:,:,:,0]\n",
    "test_data_c = im2gray(test_data)[:,:,:,0]\n",
    "valid_data_c = im2gray(valid_data)[:,:,:,0]\n",
    "\n",
    "print(train_data_c.shape, train_labels_t.shape)\n",
    "print(test_data_c.shape, test_labels.shape)\n",
    "print(valid_data_c.shape, valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GCN(image, min_divisor=1e-4):\n",
    "    \"\"\"Global Contrast Normalization\"\"\"\n",
    "    \n",
    "    imsize = image.shape[0]\n",
    "    mean = np.mean(image, axis=(1,2), dtype=float)\n",
    "    std = np.std(image, axis=(1,2), dtype=float, ddof=1)\n",
    "    std[std < min_divisor] = 1.\n",
    "    image_GCN = np.zeros(image.shape, dtype=float)\n",
    "    \n",
    "    for i in np.arange(imsize):\n",
    "        image_GCN[i,:,:] = (image[i,:,:] - mean[i]) / std[i]\n",
    "        \n",
    "    return image_GCN\n",
    "\n",
    "train_data_GCN = GCN(train_data_c)\n",
    "test_data_GCN = GCN(test_data_c)\n",
    "valid_data_GCN = GCN(valid_data_c)\n",
    "\n",
    "print(train_data_GCN.shape, train_labels_t.shape)\n",
    "print(test_data_GCN.shape, test_labels.shape)\n",
    "print(valid_data_GCN.shape, valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# logistic regression classifier\n",
    "clf = SGDClassifier(loss='hinge', penalty='l2', alpha=0.001, shuffle=True, verbose=0, \n",
    "                    n_jobs=4, random_state=None, learning_rate='optimal')\n",
    "\n",
    "clf.fit(train_data_c.reshape(train_data_GCN.shape[0],-1), train_labels_t)\n",
    "\n",
    "train_prediction = clf.predict(train_data_GCN.reshape(train_data_GCN.shape[0],-1))\n",
    "valid_prediction = clf.predict(valid_data_GCN.reshape(valid_data_GCN.shape[0],-1))\n",
    "\n",
    "print('Training score is', clf.score(train_data_GCN.reshape(train_data_GCN.shape[0],-1), train_labels_t))\n",
    "print('Validation score is', clf.score(valid_data_GCN.reshape(valid_data_GCN.shape[0],-1), valid_labels))\n",
    "print('-'*80)\n",
    "print('Classification report of training data:\\n', classification_report(train_labels_t, train_prediction))\n",
    "print('Confusion Matrix of training data:\\n', confusion_matrix(train_labels_t, train_prediction))\n",
    "\n",
    "print('Classification report of validation data:\\n', classification_report(valid_labels, valid_prediction))\n",
    "print('Confusion Matrix of validation data:\\n', confusion_matrix(valid_labels, valid_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm_clf = SVC(gamma=0.001, C=100.)\n",
    "svm_mdl = svm_clf.fit(train_data_c.reshape(train_data_GCN.shape[0],-1), train_labels_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Training score is', svm_mdl.score(train_data_GCN.reshape(train_data_GCN.shape[0],-1), train_labels_t))\n",
    "print('Validation score is', svm_mdl.score(valid_data_GCN.reshape(valid_data_GCN.shape[0],-1), valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(train_labels_t, svm_mdl.predict(train_data_GCN.reshape(train_data_GCN.shape[0],-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [opencv_env]",
   "language": "python",
   "name": "Python [opencv_env]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
