{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "# default plot stying changes\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"poster\", font_scale=1.25, rc={\"lines.linewidth\": 2.5})\n",
    "sns.set_palette(\"Set2\")\n",
    "colors = sns.color_palette('Set2',12)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pickled Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape: (7326,)\n",
      "Testing labels shape:  (2603,)\n"
     ]
    }
   ],
   "source": [
    "directory = 'generated_data'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "train_labels = np.load('{0}/train_labels.dat'.format(directory))\n",
    "test_labels = np.load('{0}/test_labels.dat'.format(directory))\n",
    "print('Training labels shape: {0}'.format(train_labels.shape))\n",
    "print('Testing labels shape:  {0}'.format(test_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Otsu's Binarization Threshold Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Otsu training shape: (7326, 640)\n",
      "Otsu testing shape:  (2603, 640)\n"
     ]
    }
   ],
   "source": [
    "train_OBT_2d = np.load('{0}/train_OBT_2d.dat'.format(directory))\n",
    "test_OBT_2d = np.load('{0}/test_OBT_2d.dat'.format(directory))\n",
    "print('Otsu training shape: {0}'.format(train_OBT_2d.shape))\n",
    "print('Otsu testing shape:  {0}'.format(test_OBT_2d.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Adaptive Mean Threshold Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive mean training shape: (7326, 640)\n",
      "Adaptive mean testing shape:  (2603, 640)\n"
     ]
    }
   ],
   "source": [
    "train_AMT_2d = np.load('{0}/train_AMT_2d.dat'.format(directory))\n",
    "test_AMT_2d = np.load('{0}/test_AMT_2d.dat'.format(directory))\n",
    "print('Adaptive mean training shape: {0}'.format(train_AMT_2d.shape))\n",
    "print('Adaptive mean testing shape:  {0}'.format(test_AMT_2d.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Adaptive Gaussian Threshold Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive Gaussian training shape: (7326, 640)\n",
      "Adaptive Gaussian testing shape:  (2603, 640)\n"
     ]
    }
   ],
   "source": [
    "train_AGT_2d = np.load('{0}/train_AGT_2d.dat'.format(directory))\n",
    "test_AGT_2d = np.load('{0}/test_AGT_2d.dat'.format(directory))\n",
    "print('Adaptive Gaussian training shape: {0}'.format(train_AGT_2d.shape))\n",
    "print('Adaptive Gaussian testing shape:  {0}'.format(test_AGT_2d.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Principle Component Analysis Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA training shape: (7326, 40)\n",
      "PCA testing shape:  (2603, 40)\n"
     ]
    }
   ],
   "source": [
    "train_PCA_2d = np.load('{0}/train_PCA_2d.dat'.format(directory))\n",
    "test_PCA_2d = np.load('{0}/test_PCA_2d.dat'.format(directory))\n",
    "print('PCA training shape: {0}'.format(train_PCA_2d.shape))\n",
    "print('PCA testing shape:  {0}'.format(test_PCA_2d.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lists of Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = ['OBT', 'AMT', 'AGT', 'PCA']\n",
    "# extended names for readability\n",
    "names_ext = ['Otsu', 'Adapt. Mean', 'Adapt. Gaussian', 'PCA']\n",
    "l_train = [train_OBT_2d, train_AMT_2d, train_AGT_2d, train_PCA_2d]\n",
    "l_test = [test_OBT_2d, test_AMT_2d, test_AGT_2d, test_PCA_2d]\n",
    "overall_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Important Pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_dir = 'imgs'\n",
    "if not os.path.exists(img_dir):\n",
    "    os.makedirs(img_dir)\n",
    "    \n",
    "def important_pixels(mdl, save_img, ht=32, wd=20):\n",
    "    '''\n",
    "    source: http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances_faces. \\\n",
    "                            html#example-ensemble-plot-forest-importances-faces-py\n",
    "    '''\n",
    "    importances = mdl.feature_importances_\n",
    "    try:\n",
    "        importances = importances.reshape(ht,wd)\n",
    "\n",
    "        # Plot pixel importances\n",
    "        plt.matshow(importances, cmap=plt.cm.hot)\n",
    "        plt.axis('off')\n",
    "        plt.savefig('{0}/{1}'.format(img_dir, save_img), bbox_inches='tight')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdl_dir = 'models'\n",
    "if not os.path.exists(mdl_dir):\n",
    "    os.makedirs(mdl_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Attributes\n",
    "# estimators_ : list of classifiers\n",
    "# classes_ : array of shape = [n_classes]\n",
    "# n_classes_ : int\n",
    "# estimator_weights_ : array of floats\n",
    "# estimator_errors_ : array of floats\n",
    "# feature_importances_ : array of shape = [n_features]\n",
    "\n",
    "ab_dict = {}\n",
    "\n",
    "for i,dataset in enumerate(l_train):\n",
    "\n",
    "    etr_clf = ExtraTreesClassifier(n_estimators=50, criterion='gini', max_depth=None, min_samples_split=4, \n",
    "                    min_samples_leaf=2, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, \n",
    "                    bootstrap=False, oob_score=False, n_jobs=-1, random_state=None, verbose=0, warm_start=False, \n",
    "                    class_weight=None)\n",
    "    \n",
    "    ab_clf = AdaBoostClassifier(base_estimator=etr_clf, n_estimators=50, learning_rate=0.1, \n",
    "                                 algorithm='SAMME.R', random_state=None)\n",
    "    \n",
    "    # cross-validation training score\n",
    "    scores = cross_val_score(ab_clf, dataset, train_labels)\n",
    "    \n",
    "    # append results to dictionary\n",
    "    ab_dict[('{0}'.format(names[i]))] = scores.mean()*100\n",
    "    \n",
    "    # models - save to disk for later use without re-running\n",
    "    ab_mdl = ab_clf.fit(dataset, train_labels) \n",
    "    \n",
    "    with open('{0}/ada_boost_{1}.pkl'.format(mdl_dir, names[i]), 'wb') as f:\n",
    "        pickle.dump(ab_mdl, f)  \n",
    "    \n",
    "    # un-comment to get pixel importance images\n",
    "    # important_pixels(ab_mdl, 'ada_boost_{0}'.format(names[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AGT': 65.465002713079571,\n",
       " 'AMT': 70.364333726592761,\n",
       " 'OBT': 69.340563686822023,\n",
       " 'PCA': 54.012240821076105}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_dict['ada_boost'] = ab_dict\n",
    "ab_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Attributes\n",
    "# base_estimator_ : list of estimators\n",
    "# estimators_ : list of estimators\n",
    "# estimators_samples_ : list of arrays\n",
    "# estimators_features_ : list of arrays\n",
    "# classes_ : array of shape = [n_classes]\n",
    "# n_classes_ : int or list\n",
    "# oob_score_ : float\n",
    "# oob_decision_function_ : array of shape = [n_samples, n_classes]\n",
    "\n",
    "bag_dict = {}\n",
    "\n",
    "for i,dataset in enumerate(l_train):\n",
    "    \n",
    "    etr_clf = ExtraTreesClassifier(n_estimators=50, criterion='gini', max_depth=None, min_samples_split=4, \n",
    "                    min_samples_leaf=2, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, \n",
    "                    bootstrap=False, oob_score=False, n_jobs=-1, random_state=None, verbose=0, warm_start=False, \n",
    "                    class_weight=None)\n",
    "    \n",
    "    bag_clf = BaggingClassifier(base_estimator=etr_clf, n_estimators=50, max_samples=1.0, max_features=1.0, \n",
    "                                bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False, \n",
    "                                n_jobs=-1, random_state=None, verbose=0)\n",
    "    # cross-validation training score\n",
    "    scores = cross_val_score(bag_clf, dataset, train_labels)\n",
    "    \n",
    "    # append results to dictionary\n",
    "    bag_dict['{0}'.format(names[i])] = scores.mean()*100\n",
    "    \n",
    "    # models - save to disk for later use without re-running\n",
    "    bag_mdl = bag_clf.fit(dataset, train_labels) \n",
    "    \n",
    "    with open('{0}/bagging_{1}.pkl'.format(mdl_dir, names[i]), 'wb') as f:\n",
    "        pickle.dump(bag_mdl, f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AGT': 68.590119006915955,\n",
       " 'AMT': 72.616524330366602,\n",
       " 'OBT': 67.838601446830609,\n",
       " 'PCA': 54.191430292289802}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_dict['bagging'] = bag_dict\n",
    "bag_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier - TAKES A LONG TIME TO RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Attributes\n",
    "# feature_importances_ : array, shape = [n_features]\n",
    "# oob_improvement_ : array, shape = [n_estimators]\n",
    "# train_score_ : array, shape = [n_estimators]\n",
    "# loss_ : LossFunction\n",
    "# init : BaseEstimator\n",
    "# estimators_ : ndarray of DecisionTreeRegressor, shape = [n_estimators, loss_.K]\n",
    "    \n",
    "gb_dict = {}\n",
    "\n",
    "n_estimators=300\n",
    "\n",
    "# min_samples_split => 0.5%-1% of total values\n",
    "min_samples_split = round(0.005*len(train_labels))\n",
    "\n",
    "# min_samples_leaf => 50\n",
    "min_samples_leaf = 50\n",
    "\n",
    "# max_depth => between 5-8\n",
    "max_depth = 6\n",
    "\n",
    "# max_features => 'sqrt' as a rule of thumb to start\n",
    "max_features = 'sqrt'\n",
    "\n",
    "# subsample => 0.8 to start\n",
    "subsample = 0.5\n",
    "\n",
    "for i,dataset in enumerate(l_train):\n",
    "    gb_clf = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=n_estimators, \n",
    "                                    subsample=subsample, min_samples_split=min_samples_split, \n",
    "                                    min_samples_leaf=min_samples_leaf, max_depth=max_depth, init=None, \n",
    "                                    random_state=None, max_features=max_features, verbose=0, \n",
    "                                    max_leaf_nodes=None, warm_start=False, presort='auto')\n",
    "    # cross-validation training score\n",
    "    scores = cross_val_score(gb_clf, dataset, train_labels)\n",
    "    \n",
    "    # append results to dictionary\n",
    "    gb_dict[('{0}'.format(names[i]))] = scores.mean()*100\n",
    "    \n",
    "    # models - save to disk for later use without re-running\n",
    "    gb_mdl = gb_clf.fit(dataset, train_labels)\n",
    "    \n",
    "    with open('{0}/gradient_boost_{1}.pkl'.format(mdl_dir, names[i]), 'wb') as f:\n",
    "        pickle.dump(gb_mdl, f)  \n",
    "    \n",
    "    # un-comment to get pixel importance images\n",
    "    # important_pixels(gb_mdl, 'gradient_boost_{0}'.format(names[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AGT': 71.538043448957609,\n",
       " 'AMT': 74.814272343448323,\n",
       " 'OBT': 67.948846842623539,\n",
       " 'PCA': 64.700360246641239}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_dict['gradient_boost'] = gb_dict\n",
    "gb_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "etr_dict = {}\n",
    "\n",
    "for i,dataset in enumerate(l_train):\n",
    "    \n",
    "    etr_clf = ExtraTreesClassifier(n_estimators=400, criterion='gini', max_depth=None, min_samples_split=4, \n",
    "                    min_samples_leaf=2, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, \n",
    "                    bootstrap=False, oob_score=False, n_jobs=-1, random_state=None, verbose=0, warm_start=False, \n",
    "                    class_weight=None)\n",
    "    \n",
    "    # cross-validation training score\n",
    "    scores = cross_val_score(etr_clf, dataset, train_labels)\n",
    "    \n",
    "    # append results to dictionary\n",
    "    etr_dict['{0}'.format(names[i])] = scores.mean()*100\n",
    "    \n",
    "    # models - save to disk for later use without re-running\n",
    "    etr_mdl = etr_clf.fit(dataset, train_labels)\n",
    "    \n",
    "    with open('{0}/extra_trees_{1}.pkl'.format(mdl_dir, names[i]), 'wb') as f:\n",
    "        pickle.dump(etr_mdl, f)  \n",
    "    \n",
    "    # un-comment to get pixel importance images\n",
    "    # important_pixels(etr_mdl, 'extra_tree{0}'.format(names[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AGT': 70.78736238080225,\n",
       " 'AMT': 74.063239226827491,\n",
       " 'OBT': 68.753316608888497,\n",
       " 'PCA': 57.972437255021582}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_dict['extra_trees'] = etr_dict\n",
    "etr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.43      0.53      0.47       180\n",
      "          1       0.65      0.83      0.73       509\n",
      "          2       0.59      0.70      0.64       394\n",
      "          3       0.46      0.48      0.47       295\n",
      "          4       0.56      0.56      0.56       256\n",
      "          5       0.55      0.52      0.53       231\n",
      "          6       0.49      0.35      0.41       199\n",
      "          7       0.65      0.53      0.59       202\n",
      "          8       0.55      0.24      0.33       175\n",
      "          9       0.51      0.27      0.35       162\n",
      "\n",
      "avg / total       0.56      0.56      0.55      2603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "etr_clf = ExtraTreesClassifier()\n",
    "etr_mdl = etr_clf.fit(train_AMT_2d, train_labels)\n",
    "print(classification_report(test_labels, etr_clf.predict(test_AMT_2d), digits=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Attributes\n",
    "# estimators_ : list of DecisionTreeClassifier\n",
    "# classes_ : array of shape = [n_classes] or a list of such arrays\n",
    "# n_classes_ : int or list\n",
    "# n_features_ : int\n",
    "# n_outputs_ : int\n",
    "# feature_importances_ : array of shape = [n_features]\n",
    "# oob_score_ : float\n",
    "# oob_decision_function_ : array of shape = [n_samples, n_classes]\n",
    "    \n",
    "rf_dict = {}\n",
    "\n",
    "for i,dataset in enumerate(l_train):\n",
    "    rf_clf = RandomForestClassifier(n_estimators=150, criterion='gini', max_depth=None, min_samples_split=2, \n",
    "                                min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', \n",
    "                                max_leaf_nodes=None, bootstrap=True, oob_score=False, n_jobs=-1, random_state=None, \n",
    "                                verbose=0, warm_start=False, class_weight=None)\n",
    "\n",
    "    # cross-validation training score\n",
    "    scores = cross_val_score(rf_clf, dataset, train_labels)\n",
    "    \n",
    "    # append results to dictionary\n",
    "    rf_dict['{0}'.format(names[i])] = scores.mean()*100\n",
    "    \n",
    "    # models - save to disk for later use without re-running\n",
    "    rf_mdl = rf_clf.fit(dataset, train_labels)\n",
    "    \n",
    "    with open('{0}/random_forrest_{1}.pkl'.format(mdl_dir, names[i]), 'wb') as f:\n",
    "        pickle.dump(rf_mdl, f)  \n",
    "    \n",
    "    # un-comment to get pixel importance images\n",
    "    # important_pixels(rf_mdl, 'random_forrest{0}'.format(names[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AGT': 66.733920586248189,\n",
       " 'AMT': 71.059849271052315,\n",
       " 'OBT': 67.238764728383458,\n",
       " 'PCA': 59.951721980948633}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_dict['random_forrest'] = rf_dict\n",
    "rf_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "    \n",
    "knn_dict = {}\n",
    "\n",
    "for i,dataset in enumerate(l_train):\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=10, weights='uniform', algorithm='auto', leaf_size=30, p=2, \n",
    "                                   metric='minkowski', metric_params=None, n_jobs=-1)\n",
    "\n",
    "    # cross-validation training score\n",
    "    scores = cross_val_score(knn_clf, dataset, train_labels)\n",
    "    \n",
    "    # append results to dictionary\n",
    "    knn_dict['{0}'.format(names[i])] = scores.mean()*100\n",
    "    \n",
    "    # models - save to disk for later use without re-running\n",
    "    knn_mdl = knn_clf.fit(dataset, train_labels)\n",
    "    \n",
    "    with open('{0}/kneighbors_{1}.pkl'.format(mdl_dir, names[i]), 'wb') as f:\n",
    "        pickle.dump(knn_mdl, f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AGT': 60.742378737080713,\n",
       " 'AMT': 63.82636031674128,\n",
       " 'OBT': 57.139520969711967,\n",
       " 'PCA': 61.683895836072068}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_dict['kneighbors'] = knn_dict\n",
    "knn_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_dict = {}\n",
    "\n",
    "C = [1, 10, 100]\n",
    "gamma = [0.1, 0.01, 0.01, 0.001]\n",
    "\n",
    "for i,dataset in enumerate(l_train):\n",
    "    for c in C:\n",
    "        for g in gamma:\n",
    "            svc_clf = SVC(C=c, kernel='rbf', degree=3, gamma=g, coef0=0.0, shrinking=True, probability=False, \n",
    "                          tol=0.001, cache_size=1000, class_weight=None, verbose=False, max_iter=-1, \n",
    "                          decision_function_shape=None)\n",
    "\n",
    "            # cross-validation training score\n",
    "            scores = cross_val_score(svc_clf, dataset, train_labels)\n",
    "\n",
    "            # append results to dictionary\n",
    "            svc_dict[('{0}'.format(names[i]), c, g)] = scores.mean()*100\n",
    "\n",
    "            # models - save to disk for later use without re-running\n",
    "            svc_mdl = svc_clf.fit(dataset, train_labels)\n",
    "\n",
    "            with open('{0}/svc_{1}-{2}-{3}.pkl'.format(mdl_dir, names[i], c, g), 'wb') as f:\n",
    "                pickle.dump(svc_mdl, f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('AGT', 1, 0.001): 19.178291874734157,\n",
       " ('AGT', 1, 0.01): 19.178291874734157,\n",
       " ('AGT', 1, 0.1): 19.178291874734157,\n",
       " ('AGT', 10, 0.001): 19.178291874734157,\n",
       " ('AGT', 10, 0.01): 19.178291874734157,\n",
       " ('AGT', 10, 0.1): 19.178291874734157,\n",
       " ('AGT', 100, 0.001): 19.178291874734157,\n",
       " ('AGT', 100, 0.01): 19.178291874734157,\n",
       " ('AGT', 100, 0.1): 19.178291874734157,\n",
       " ('AMT', 1, 0.001): 19.178291874734157,\n",
       " ('AMT', 1, 0.01): 19.178291874734157,\n",
       " ('AMT', 1, 0.1): 19.178291874734157,\n",
       " ('AMT', 10, 0.001): 19.178291874734157,\n",
       " ('AMT', 10, 0.01): 19.178291874734157,\n",
       " ('AMT', 10, 0.1): 19.178291874734157,\n",
       " ('AMT', 100, 0.001): 19.178291874734157,\n",
       " ('AMT', 100, 0.01): 19.178291874734157,\n",
       " ('AMT', 100, 0.1): 19.178291874734157,\n",
       " ('OBT', 1, 0.001): 19.178291874734157,\n",
       " ('OBT', 1, 0.01): 19.178291874734157,\n",
       " ('OBT', 1, 0.1): 19.178291874734157,\n",
       " ('OBT', 10, 0.001): 19.178291874734157,\n",
       " ('OBT', 10, 0.01): 19.178291874734157,\n",
       " ('OBT', 10, 0.1): 19.178291874734157,\n",
       " ('OBT', 100, 0.001): 19.178291874734157,\n",
       " ('OBT', 100, 0.01): 19.178291874734157,\n",
       " ('OBT', 100, 0.1): 19.178291874734157,\n",
       " ('PCA', 1, 0.001): 20.638583887499806,\n",
       " ('PCA', 1, 0.01): 50.546196717500855,\n",
       " ('PCA', 1, 0.1): 53.384410535167817,\n",
       " ('PCA', 10, 0.001): 29.839407927945636,\n",
       " ('PCA', 10, 0.01): 69.286070768176174,\n",
       " ('PCA', 10, 0.1): 56.755664486693689,\n",
       " ('PCA', 100, 0.001): 52.442809391446531,\n",
       " ('PCA', 100, 0.01): 69.873352675333507,\n",
       " ('PCA', 100, 0.1): 56.701103392863715}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_dict['svc'] = svc_dict\n",
    "svc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('random_forrest',\n",
       "  {'AGT': 66.733920586248189,\n",
       "   'AMT': 71.059849271052315,\n",
       "   'OBT': 67.238764728383458,\n",
       "   'PCA': 59.951721980948633}),\n",
       " ('gradient_boost',\n",
       "  {'AGT': 71.538043448957609,\n",
       "   'AMT': 74.814272343448323,\n",
       "   'OBT': 67.948846842623539,\n",
       "   'PCA': 64.700360246641239}),\n",
       " ('extra_trees',\n",
       "  {'AGT': 70.78736238080225,\n",
       "   'AMT': 74.063239226827491,\n",
       "   'OBT': 68.753316608888497,\n",
       "   'PCA': 57.972437255021582}),\n",
       " ('bagging',\n",
       "  {'AGT': 68.590119006915955,\n",
       "   'AMT': 72.616524330366602,\n",
       "   'OBT': 67.838601446830609,\n",
       "   'PCA': 54.191430292289802}),\n",
       " ('ada_boost',\n",
       "  {'AGT': 65.465002713079571,\n",
       "   'AMT': 70.364333726592761,\n",
       "   'OBT': 69.340563686822023,\n",
       "   'PCA': 54.012240821076105}),\n",
       " ('svc',\n",
       "  {('AGT', 1, 0.001): 19.178291874734157,\n",
       "   ('AGT', 1, 0.01): 19.178291874734157,\n",
       "   ('AGT', 1, 0.1): 19.178291874734157,\n",
       "   ('AGT', 10, 0.001): 19.178291874734157,\n",
       "   ('AGT', 10, 0.01): 19.178291874734157,\n",
       "   ('AGT', 10, 0.1): 19.178291874734157,\n",
       "   ('AGT', 100, 0.001): 19.178291874734157,\n",
       "   ('AGT', 100, 0.01): 19.178291874734157,\n",
       "   ('AGT', 100, 0.1): 19.178291874734157,\n",
       "   ('AMT', 1, 0.001): 19.178291874734157,\n",
       "   ('AMT', 1, 0.01): 19.178291874734157,\n",
       "   ('AMT', 1, 0.1): 19.178291874734157,\n",
       "   ('AMT', 10, 0.001): 19.178291874734157,\n",
       "   ('AMT', 10, 0.01): 19.178291874734157,\n",
       "   ('AMT', 10, 0.1): 19.178291874734157,\n",
       "   ('AMT', 100, 0.001): 19.178291874734157,\n",
       "   ('AMT', 100, 0.01): 19.178291874734157,\n",
       "   ('AMT', 100, 0.1): 19.178291874734157,\n",
       "   ('OBT', 1, 0.001): 19.178291874734157,\n",
       "   ('OBT', 1, 0.01): 19.178291874734157,\n",
       "   ('OBT', 1, 0.1): 19.178291874734157,\n",
       "   ('OBT', 10, 0.001): 19.178291874734157,\n",
       "   ('OBT', 10, 0.01): 19.178291874734157,\n",
       "   ('OBT', 10, 0.1): 19.178291874734157,\n",
       "   ('OBT', 100, 0.001): 19.178291874734157,\n",
       "   ('OBT', 100, 0.01): 19.178291874734157,\n",
       "   ('OBT', 100, 0.1): 19.178291874734157,\n",
       "   ('PCA', 1, 0.001): 20.638583887499806,\n",
       "   ('PCA', 1, 0.01): 50.546196717500855,\n",
       "   ('PCA', 1, 0.1): 53.384410535167817,\n",
       "   ('PCA', 10, 0.001): 29.839407927945636,\n",
       "   ('PCA', 10, 0.01): 69.286070768176174,\n",
       "   ('PCA', 10, 0.1): 56.755664486693689,\n",
       "   ('PCA', 100, 0.001): 52.442809391446531,\n",
       "   ('PCA', 100, 0.01): 69.873352675333507,\n",
       "   ('PCA', 100, 0.1): 56.701103392863715}),\n",
       " ('kneighbors',\n",
       "  {'AGT': 60.742378737080713,\n",
       "   'AMT': 63.82636031674128,\n",
       "   'OBT': 57.139520969711967,\n",
       "   'PCA': 61.683895836072068})]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(overall_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get model names\n",
    "mdls = [k for k,v in overall_dict.items()]\n",
    "\n",
    "# get cross fold scores for each model\n",
    "lst_cnts = [[v for k,v in overall_dict[mdl].items()] for mdl in mdls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "incompatible sizes: argument 'height' must be length 5 or scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-ab8dd92d4243>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     plt.bar(pos[i], lst_cnts[i], width=width, align='center', color=colors[i], alpha=0.8, edgecolor='w', \n\u001b[0;32m---> 23\u001b[0;31m             label=mdls[i])\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# labels/titles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(left, height, width, bottom, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   2641\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2642\u001b[0m         ret = ax.bar(left, height, width=width, bottom=bottom, data=data,\n\u001b[0;32m-> 2643\u001b[0;31m                      **kwargs)\n\u001b[0m\u001b[1;32m   2644\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2645\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwashold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1810\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1811\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1812\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1813\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, left, height, width, bottom, **kwargs)\u001b[0m\n\u001b[1;32m   2078\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnbars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2079\u001b[0m             raise ValueError(\"incompatible sizes: argument 'height' \"\n\u001b[0;32m-> 2080\u001b[0;31m                               \"must be length %d or scalar\" % nbars)\n\u001b[0m\u001b[1;32m   2081\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnbars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m             raise ValueError(\"incompatible sizes: argument 'width' \"\n",
      "\u001b[0;31mValueError\u001b[0m: incompatible sizes: argument 'height' must be length 5 or scalar"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJ8AAALTCAYAAAC4x6NcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4RMAAAAAAABs8z+0LGYgW9uBwQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c35ab710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# colors\n",
    "sns.set_palette(\"hot\")\n",
    "colors = sns.color_palette('hot',9)\n",
    "\n",
    "# make figure\n",
    "fig = plt.figure(figsize=(20,12))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# spacing/size\n",
    "width = 0.1\n",
    "steps = [-0.4, -0.3, -0.2, -0.1, 0, 0.1, 0.2, 0.3, 0.4]\n",
    "pos = []\n",
    "for j in steps:\n",
    "    temp = []\n",
    "    for k in range(1,6):\n",
    "        temp.append(k+j)\n",
    "    pos.append(temp)\n",
    "pos\n",
    "\n",
    "# plots\n",
    "for i in range(9):\n",
    "    plt.bar(pos[i], lst_cnts[i], width=width, align='center', color=colors[i], alpha=0.8, edgecolor='w', \n",
    "            label=mdls[i])\n",
    "\n",
    "# labels/titles\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('Threshold Technique')\n",
    "plt.ylabel('CFV Score')\n",
    "plt.title('Accuracy by Model and Threshold')\n",
    "\n",
    "ticks = range(1,6)\n",
    "plt.xlim(0.5,5.5)\n",
    "plt.xticks(ticks, names_ext)\n",
    "plt.ylim(0,100)\n",
    "\n",
    "# remove border\n",
    "ax.spines[\"top\"].set_visible(False)  \n",
    "ax.spines[\"right\"].set_visible(False) \n",
    "ax.spines[\"bottom\"].set_visible(False) \n",
    "ax.spines[\"left\"].set_visible(False)\n",
    "\n",
    "# show grid\n",
    "ax.yaxis.grid(True) \n",
    "\n",
    "# plot that biddy\n",
    "plt.tight_layout()\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ada_boost</th>\n",
       "      <th>bagging</th>\n",
       "      <th>extra_trees</th>\n",
       "      <th>gradient_boost</th>\n",
       "      <th>kneighbors</th>\n",
       "      <th>random_forrest</th>\n",
       "      <th>svc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AGT</th>\n",
       "      <td>65.465003</td>\n",
       "      <td>68.590119</td>\n",
       "      <td>70.787362</td>\n",
       "      <td>71.538043</td>\n",
       "      <td>60.742379</td>\n",
       "      <td>66.733921</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMT</th>\n",
       "      <td>70.364334</td>\n",
       "      <td>72.616524</td>\n",
       "      <td>74.063239</td>\n",
       "      <td>74.814272</td>\n",
       "      <td>63.826360</td>\n",
       "      <td>71.059849</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBT</th>\n",
       "      <td>69.340564</td>\n",
       "      <td>67.838601</td>\n",
       "      <td>68.753317</td>\n",
       "      <td>67.948847</td>\n",
       "      <td>57.139521</td>\n",
       "      <td>67.238765</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA</th>\n",
       "      <td>54.012241</td>\n",
       "      <td>54.191430</td>\n",
       "      <td>57.972437</td>\n",
       "      <td>64.700360</td>\n",
       "      <td>61.683896</td>\n",
       "      <td>59.951722</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(OBT, 1, 0.1)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.178292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(OBT, 10, 0.001)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.178292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(AMT, 1, 0.1)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.178292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(OBT, 10, 0.1)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.178292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(OBT, 1, 0.001)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.178292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(AMT, 100, 0.01)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.178292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(AGT, 100, 0.01)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.178292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(PCA, 1, 0.001)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.638584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(OBT, 100, 0.01)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.178292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(PCA, 10, 0.001)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.839408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(AGT, 10, 0.01)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.178292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(PCA, 100, 0.001)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.442809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(OBT, 100, 0.1)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.178292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(PCA, 100, 0.01)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.873353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(AMT, 100, 0.1)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.178292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(AGT, 100, 0.1)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.178292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(AGT, 10, 0.001)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.178292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(AMT, 10, 0.1)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.178292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(PCA, 100, 0.1)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.701103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(AMT, 10, 0.001)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.178292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(PCA, 10, 0.1)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.755664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(AMT, 10, 0.01)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.178292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(AGT, 100, 0.001)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.178292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(AMT, 100, 0.001)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.178292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(OBT, 100, 0.001)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.178292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(PCA, 10, 0.01)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.286071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(PCA, 1, 0.01)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.546197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(OBT, 1, 0.01)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.178292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(AMT, 1, 0.01)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.178292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(PCA, 1, 0.1)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.384411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(AGT, 1, 0.01)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.178292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(AMT, 1, 0.001)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.178292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(AGT, 1, 0.001)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.178292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(AGT, 10, 0.1)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.178292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(AGT, 1, 0.1)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.178292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(OBT, 10, 0.01)</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.178292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ada_boost    bagging  extra_trees  gradient_boost  \\\n",
       "AGT                65.465003  68.590119    70.787362       71.538043   \n",
       "AMT                70.364334  72.616524    74.063239       74.814272   \n",
       "OBT                69.340564  67.838601    68.753317       67.948847   \n",
       "PCA                54.012241  54.191430    57.972437       64.700360   \n",
       "(OBT, 1, 0.1)            NaN        NaN          NaN             NaN   \n",
       "(OBT, 10, 0.001)         NaN        NaN          NaN             NaN   \n",
       "(AMT, 1, 0.1)            NaN        NaN          NaN             NaN   \n",
       "(OBT, 10, 0.1)           NaN        NaN          NaN             NaN   \n",
       "(OBT, 1, 0.001)          NaN        NaN          NaN             NaN   \n",
       "(AMT, 100, 0.01)         NaN        NaN          NaN             NaN   \n",
       "(AGT, 100, 0.01)         NaN        NaN          NaN             NaN   \n",
       "(PCA, 1, 0.001)          NaN        NaN          NaN             NaN   \n",
       "(OBT, 100, 0.01)         NaN        NaN          NaN             NaN   \n",
       "(PCA, 10, 0.001)         NaN        NaN          NaN             NaN   \n",
       "(AGT, 10, 0.01)          NaN        NaN          NaN             NaN   \n",
       "(PCA, 100, 0.001)        NaN        NaN          NaN             NaN   \n",
       "(OBT, 100, 0.1)          NaN        NaN          NaN             NaN   \n",
       "(PCA, 100, 0.01)         NaN        NaN          NaN             NaN   \n",
       "(AMT, 100, 0.1)          NaN        NaN          NaN             NaN   \n",
       "(AGT, 100, 0.1)          NaN        NaN          NaN             NaN   \n",
       "(AGT, 10, 0.001)         NaN        NaN          NaN             NaN   \n",
       "(AMT, 10, 0.1)           NaN        NaN          NaN             NaN   \n",
       "(PCA, 100, 0.1)          NaN        NaN          NaN             NaN   \n",
       "(AMT, 10, 0.001)         NaN        NaN          NaN             NaN   \n",
       "(PCA, 10, 0.1)           NaN        NaN          NaN             NaN   \n",
       "(AMT, 10, 0.01)          NaN        NaN          NaN             NaN   \n",
       "(AGT, 100, 0.001)        NaN        NaN          NaN             NaN   \n",
       "(AMT, 100, 0.001)        NaN        NaN          NaN             NaN   \n",
       "(OBT, 100, 0.001)        NaN        NaN          NaN             NaN   \n",
       "(PCA, 10, 0.01)          NaN        NaN          NaN             NaN   \n",
       "(PCA, 1, 0.01)           NaN        NaN          NaN             NaN   \n",
       "(OBT, 1, 0.01)           NaN        NaN          NaN             NaN   \n",
       "(AMT, 1, 0.01)           NaN        NaN          NaN             NaN   \n",
       "(PCA, 1, 0.1)            NaN        NaN          NaN             NaN   \n",
       "(AGT, 1, 0.01)           NaN        NaN          NaN             NaN   \n",
       "(AMT, 1, 0.001)          NaN        NaN          NaN             NaN   \n",
       "(AGT, 1, 0.001)          NaN        NaN          NaN             NaN   \n",
       "(AGT, 10, 0.1)           NaN        NaN          NaN             NaN   \n",
       "(AGT, 1, 0.1)            NaN        NaN          NaN             NaN   \n",
       "(OBT, 10, 0.01)          NaN        NaN          NaN             NaN   \n",
       "\n",
       "                   kneighbors  random_forrest        svc  \n",
       "AGT                 60.742379       66.733921        NaN  \n",
       "AMT                 63.826360       71.059849        NaN  \n",
       "OBT                 57.139521       67.238765        NaN  \n",
       "PCA                 61.683896       59.951722        NaN  \n",
       "(OBT, 1, 0.1)             NaN             NaN  19.178292  \n",
       "(OBT, 10, 0.001)          NaN             NaN  19.178292  \n",
       "(AMT, 1, 0.1)             NaN             NaN  19.178292  \n",
       "(OBT, 10, 0.1)            NaN             NaN  19.178292  \n",
       "(OBT, 1, 0.001)           NaN             NaN  19.178292  \n",
       "(AMT, 100, 0.01)          NaN             NaN  19.178292  \n",
       "(AGT, 100, 0.01)          NaN             NaN  19.178292  \n",
       "(PCA, 1, 0.001)           NaN             NaN  20.638584  \n",
       "(OBT, 100, 0.01)          NaN             NaN  19.178292  \n",
       "(PCA, 10, 0.001)          NaN             NaN  29.839408  \n",
       "(AGT, 10, 0.01)           NaN             NaN  19.178292  \n",
       "(PCA, 100, 0.001)         NaN             NaN  52.442809  \n",
       "(OBT, 100, 0.1)           NaN             NaN  19.178292  \n",
       "(PCA, 100, 0.01)          NaN             NaN  69.873353  \n",
       "(AMT, 100, 0.1)           NaN             NaN  19.178292  \n",
       "(AGT, 100, 0.1)           NaN             NaN  19.178292  \n",
       "(AGT, 10, 0.001)          NaN             NaN  19.178292  \n",
       "(AMT, 10, 0.1)            NaN             NaN  19.178292  \n",
       "(PCA, 100, 0.1)           NaN             NaN  56.701103  \n",
       "(AMT, 10, 0.001)          NaN             NaN  19.178292  \n",
       "(PCA, 10, 0.1)            NaN             NaN  56.755664  \n",
       "(AMT, 10, 0.01)           NaN             NaN  19.178292  \n",
       "(AGT, 100, 0.001)         NaN             NaN  19.178292  \n",
       "(AMT, 100, 0.001)         NaN             NaN  19.178292  \n",
       "(OBT, 100, 0.001)         NaN             NaN  19.178292  \n",
       "(PCA, 10, 0.01)           NaN             NaN  69.286071  \n",
       "(PCA, 1, 0.01)            NaN             NaN  50.546197  \n",
       "(OBT, 1, 0.01)            NaN             NaN  19.178292  \n",
       "(AMT, 1, 0.01)            NaN             NaN  19.178292  \n",
       "(PCA, 1, 0.1)             NaN             NaN  53.384411  \n",
       "(AGT, 1, 0.01)            NaN             NaN  19.178292  \n",
       "(AMT, 1, 0.001)           NaN             NaN  19.178292  \n",
       "(AGT, 1, 0.001)           NaN             NaN  19.178292  \n",
       "(AGT, 10, 0.1)            NaN             NaN  19.178292  \n",
       "(AGT, 1, 0.1)             NaN             NaN  19.178292  \n",
       "(OBT, 10, 0.01)           NaN             NaN  19.178292  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(overall_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make figure\n",
    "fig = plt.figure(figsize=(20,12))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# plots\n",
    "ax = sns.heatmap(df, annot=True, cmap=\"hot_r\", alpha=0.8, linewidths=.1, vmin=0, vmax=100)\n",
    "\n",
    "# labels/titles\n",
    "plt.title('Accuracy by Model and Threshold')\n",
    "\n",
    "# remove border\n",
    "ax.spines[\"top\"].set_visible(False)  \n",
    "ax.spines[\"right\"].set_visible(False) \n",
    "ax.spines[\"bottom\"].set_visible(False) \n",
    "ax.spines[\"left\"].set_visible(False)\n",
    "\n",
    "# show grid\n",
    "ax.yaxis.grid(False) \n",
    "\n",
    "# plot that biddy\n",
    "plt.tight_layout()\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "'''\n",
    "word = 'fubar'\n",
    "reg_agt = re.compile(r'AGT')\n",
    "if reg_agt.search(word) is not None:\n",
    "  print 'matched'\n",
    "'''\n",
    "# l_test = [test_OBT_2d, test_AMT_2d, test_AGT_2d, test_PCA_2d]\n",
    "\n",
    "with open('tuned_resuts.csv', 'a') as f:\n",
    "\n",
    "    for fil in os.listdir('models'):\n",
    "        if fil[-3:] == 'pkl':\n",
    "\n",
    "            reg_agt = re.compile(r'AGT')\n",
    "            if reg_agt.search(fil) is not None:\n",
    "                #AGT\n",
    "                with open('models/{0}'.format(fil), 'rb') as fid:\n",
    "                    mdl = pickle.load(fid)\n",
    "                    score = accuracy_score(test_labels, mdl.predict(test_AGT_2d))\n",
    "                    f.write('{0}, {1}\\n'.format(fil[:-4], score))\n",
    "                    clf = None\n",
    "\n",
    "            reg_agt = re.compile(r'AMT')\n",
    "            if reg_agt.search(fil) is not None:\n",
    "                #AMT\n",
    "                with open('models/{0}'.format(fil), 'rb') as fid:\n",
    "                    mdl = pickle.load(fid)\n",
    "                    score = accuracy_score(test_labels, mdl.predict(test_AMT_2d))\n",
    "                    f.write('{0}, {1}\\n'.format(fil[:-4], score))\n",
    "                    clf = None\n",
    "\n",
    "            reg_pca = re.compile(r'PCA')\n",
    "            if reg_pca.search(fil) is not None:\n",
    "                #PCA\n",
    "                with open('models/{0}'.format(fil), 'rb') as fid:\n",
    "                    mdl = pickle.load(fid)\n",
    "                    score = accuracy_score(test_labels, mdl.predict(test_PCA_2d))\n",
    "                    f.write('{0}, {1}\\n'.format(fil[:-4], score))\n",
    "                    clf = None\n",
    "\n",
    "            reg_obt = re.compile(r'OBT')\n",
    "            if reg_obt.search(fil) is not None:\n",
    "                #OBT\n",
    "                with open('models/{0}'.format(fil), 'rb') as fid:\n",
    "                    mdl = pickle.load(fid)\n",
    "                    score = accuracy_score(test_labels, mdl.predict(test_OBT_2d))\n",
    "                    f.write('{0}, {1}\\n'.format(fil[:-4], score))\n",
    "                    clf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mdl</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gradient_boost_AMT</td>\n",
       "      <td>0.719939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>extra_trees_AMT</td>\n",
       "      <td>0.711103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bagging_AMT</td>\n",
       "      <td>0.699193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gradient_boost_AGT</td>\n",
       "      <td>0.689589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>random_forrest_AMT</td>\n",
       "      <td>0.683826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>extra_trees_AGT</td>\n",
       "      <td>0.678448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ada_boost_AMT</td>\n",
       "      <td>0.667307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bagging_AGT</td>\n",
       "      <td>0.657703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ada_boost_OBT</td>\n",
       "      <td>0.656166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gradient_boost_OBT</td>\n",
       "      <td>0.651556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   mdl  accuracy\n",
       "13  gradient_boost_AMT  0.719939\n",
       "9      extra_trees_AMT  0.711103\n",
       "5          bagging_AMT  0.699193\n",
       "12  gradient_boost_AGT  0.689589\n",
       "21  random_forrest_AMT  0.683826\n",
       "8      extra_trees_AGT  0.678448\n",
       "1        ada_boost_AMT  0.667307\n",
       "4          bagging_AGT  0.657703\n",
       "2        ada_boost_OBT  0.656166\n",
       "14  gradient_boost_OBT  0.651556"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tuned_resuts.csv',  names=['mdl', 'accuracy'])\n",
    "df = df.sort_values('accuracy', ascending=False)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.66      0.70       180\n",
      "          1       0.78      0.87      0.82       509\n",
      "          2       0.72      0.85      0.78       394\n",
      "          3       0.61      0.63      0.62       295\n",
      "          4       0.73      0.72      0.73       256\n",
      "          5       0.67      0.72      0.69       231\n",
      "          6       0.63      0.59      0.61       199\n",
      "          7       0.79      0.68      0.73       202\n",
      "          8       0.77      0.51      0.61       175\n",
      "          9       0.73      0.58      0.65       162\n",
      "\n",
      "avg / total       0.72      0.72      0.72      2603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fid = open('models/gradient_boost_AMT.pkl', 'rb')\n",
    "mdl = pickle.load(fid)\n",
    "\n",
    "print(classification_report(test_labels, mdl.predict(test_AMT_2d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Attributes\n",
    "# feature_importances_ : array, shape = [n_features]\n",
    "# oob_improvement_ : array, shape = [n_estimators]\n",
    "# train_score_ : array, shape = [n_estimators]\n",
    "# loss_ : LossFunction\n",
    "# init : BaseEstimator\n",
    "# estimators_ : ndarray of DecisionTreeRegressor, shape = [n_estimators, loss_.K]\n",
    "    \n",
    "gb_dict = {}\n",
    "\n",
    "n_estimators=300\n",
    "\n",
    "# min_samples_split => 0.5%-1% of total values\n",
    "min_samples_split = round(0.005*len(train_labels))\n",
    "\n",
    "# min_samples_leaf => 50\n",
    "min_samples_leaf = 50\n",
    "\n",
    "# max_depth => between 5-8\n",
    "max_depth = 6\n",
    "\n",
    "# max_features => 'sqrt' as a rule of thumb to start\n",
    "max_features = 'sqrt'\n",
    "\n",
    "# subsample => 0.8 to start\n",
    "subsample = 0.5\n",
    "\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=n_estimators, \n",
    "                                subsample=subsample, min_samples_split=min_samples_split, \n",
    "                                min_samples_leaf=min_samples_leaf, max_depth=max_depth, init=None, \n",
    "                                random_state=None, max_features=max_features, verbose=0, \n",
    "                                max_leaf_nodes=None, warm_start=False, presort='auto')\n",
    "\n",
    "# cross-validation training score\n",
    "scores = cross_val_score(gb_clf, train_AMT_2d, train_labels)\n",
    "\n",
    "gb_mdl = gb_clf.fit(train_AMT_2d, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_pred = gb_mdl.predict_proba(test_AMT_2d)\n",
    "y_test_predicted = gb_mdl.predict(test_AMT_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-99c0ec02b7e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    255\u001b[0m     return _average_binary_score(\n\u001b[1;32m    256\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "roc_auc_score(test_labels, p_pred[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data is not binary and pos_label is not specified",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-0c1b053c485c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfalse_positive_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_positive_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \"\"\"\n\u001b[1;32m    500\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 501\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    306\u001b[0m              \u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m              array_equal(classes, [1]))):\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data is not binary and pos_label is not specified\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mpos_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data is not binary and pos_label is not specified"
     ]
    }
   ],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(test_labels, p_pred[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print(roc_auc_score(test_labels, mdl.predict(test_AMT_2d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fid.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
